<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 데이터 마이닝 | Introduction to Big Data Science</title>
  <meta name="description" content="Chapter 6 데이터 마이닝 | Introduction to Big Data Science" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 데이터 마이닝 | Introduction to Big Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 6 데이터 마이닝 | Introduction to Big Data Science" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 데이터 마이닝 | Introduction to Big Data Science" />
  
  <meta name="twitter:description" content="Chapter 6 데이터 마이닝 | Introduction to Big Data Science" />
  

<meta name="author" content="Jin Hyun Nam" />


<meta name="date" content="2025-02-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter5.html"/>
<link rel="next" href="chapter7.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contents"><i class="fa fa-check"></i>Contents</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> 데이터와 데이터 과학자</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#데이터"><i class="fa fa-check"></i><b>1.1</b> 데이터</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="chapter1.html"><a href="chapter1.html#데이터-수집의-역사"><i class="fa fa-check"></i><b>1.1.1</b> 데이터 수집의 역사</a></li>
<li class="chapter" data-level="1.1.2" data-path="chapter1.html"><a href="chapter1.html#데이터마이닝---데이터-분석과-it의-본격적인-만남"><i class="fa fa-check"></i><b>1.1.2</b> 데이터마이닝 - 데이터 분석과 IT의 본격적인 만남</a></li>
<li class="chapter" data-level="1.1.3" data-path="chapter1.html"><a href="chapter1.html#빅데이터-시대의-도래"><i class="fa fa-check"></i><b>1.1.3</b> 빅데이터 시대의 도래</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#데이터-과학-데이터-과학자"><i class="fa fa-check"></i><b>1.2</b> 데이터 과학, 데이터 과학자</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="chapter1.html"><a href="chapter1.html#데이터-과학-데이터-과학자의-유래"><i class="fa fa-check"></i><b>1.2.1</b> 데이터 과학, 데이터 과학자의 유래</a></li>
<li class="chapter" data-level="1.2.2" data-path="chapter1.html"><a href="chapter1.html#왜-데이터-과학자인가"><i class="fa fa-check"></i><b>1.2.2</b> 왜 데이터 과학자인가?</a></li>
<li class="chapter" data-level="1.2.3" data-path="chapter1.html"><a href="chapter1.html#데이터-과학자가-되려면"><i class="fa fa-check"></i><b>1.2.3</b> 데이터 과학자가 되려면</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> 데이터 사이언스로 여는 세상</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#서론"><i class="fa fa-check"></i><b>2.1</b> 서론</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#편리한-사회"><i class="fa fa-check"></i><b>2.2</b> 편리한 사회</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="chapter2.html"><a href="chapter2.html#추천-서비스"><i class="fa fa-check"></i><b>2.2.1</b> 추천 서비스</a></li>
<li class="chapter" data-level="2.2.2" data-path="chapter2.html"><a href="chapter2.html#맞춤형-개인화-서비스"><i class="fa fa-check"></i><b>2.2.2</b> 맞춤형 개인화 서비스</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#윤택한-사회"><i class="fa fa-check"></i><b>2.3</b> 윤택한 사회</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="chapter2.html"><a href="chapter2.html#건강한-삶"><i class="fa fa-check"></i><b>2.3.1</b> 건강한 삶</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter2.html"><a href="chapter2.html#연결된-사회"><i class="fa fa-check"></i><b>2.3.2</b> 연결된 사회</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#안전한-사회"><i class="fa fa-check"></i><b>2.4</b> 안전한 사회</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="chapter2.html"><a href="chapter2.html#위험-조기포착을-통한-평안한-사회-실현"><i class="fa fa-check"></i><b>2.4.1</b> 위험 조기포착을 통한 평안한 사회 실현</a></li>
<li class="chapter" data-level="2.4.2" data-path="chapter2.html"><a href="chapter2.html#부정행위-방지를-통한-건전한-사회-실현"><i class="fa fa-check"></i><b>2.4.2</b> 부정행위 방지를 통한 건전한 사회 실현</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> 데이터 구조</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#데이터의-구조"><i class="fa fa-check"></i><b>3.1</b> 데이터의 구조</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="chapter3.html"><a href="chapter3.html#데이터의-기초개념"><i class="fa fa-check"></i><b>3.1.1</b> 데이터의 기초개념</a></li>
<li class="chapter" data-level="3.1.2" data-path="chapter3.html"><a href="chapter3.html#데이터의-속성"><i class="fa fa-check"></i><b>3.1.2</b> 데이터의 속성</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#데이터의-저장"><i class="fa fa-check"></i><b>3.2</b> 데이터의 저장</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="chapter3.html"><a href="chapter3.html#데이터의-분류"><i class="fa fa-check"></i><b>3.2.1</b> 데이터의 분류</a></li>
<li class="chapter" data-level="3.2.2" data-path="chapter3.html"><a href="chapter3.html#데이터의-수집"><i class="fa fa-check"></i><b>3.2.2</b> 데이터의 수집</a></li>
<li class="chapter" data-level="3.2.3" data-path="chapter3.html"><a href="chapter3.html#데이터베이스"><i class="fa fa-check"></i><b>3.2.3</b> 데이터베이스</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> 데이터 기반 의사결정</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#데이터-품질관리"><i class="fa fa-check"></i><b>4.1</b> 데이터 품질관리</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="chapter4.html"><a href="chapter4.html#데이터-품질관리의-의의"><i class="fa fa-check"></i><b>4.1.1</b> 데이터 품질관리의 의의</a></li>
<li class="chapter" data-level="4.1.2" data-path="chapter4.html"><a href="chapter4.html#데이터-품질관리-시스템"><i class="fa fa-check"></i><b>4.1.2</b> 데이터 품질관리 시스템</a></li>
<li class="chapter" data-level="4.1.3" data-path="chapter4.html"><a href="chapter4.html#데이터-분석"><i class="fa fa-check"></i><b>4.1.3</b> 데이터 분석</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#데이터-기반의-의사결정"><i class="fa fa-check"></i><b>4.2</b> 데이터 기반의 의사결정</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="chapter4.html"><a href="chapter4.html#데이터-과학자와-의사결정"><i class="fa fa-check"></i><b>4.2.1</b> 데이터 과학자와 의사결정</a></li>
<li class="chapter" data-level="4.2.2" data-path="chapter4.html"><a href="chapter4.html#데이터-기반-의사결정"><i class="fa fa-check"></i><b>4.2.2</b> 데이터 기반 의사결정</a></li>
<li class="chapter" data-level="4.2.3" data-path="chapter4.html"><a href="chapter4.html#의사결정의-지원"><i class="fa fa-check"></i><b>4.2.3</b> 의사결정의 지원</a></li>
<li class="chapter" data-level="4.2.4" data-path="chapter4.html"><a href="chapter4.html#통계적-문제해결"><i class="fa fa-check"></i><b>4.2.4</b> 통계적 문제해결</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#데이터와-프레젠테이션"><i class="fa fa-check"></i><b>4.3</b> 데이터와 프레젠테이션</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="chapter4.html"><a href="chapter4.html#프레젠테이션의-의의"><i class="fa fa-check"></i><b>4.3.1</b> 프레젠테이션의 의의</a></li>
<li class="chapter" data-level="4.3.2" data-path="chapter4.html"><a href="chapter4.html#효과적인-프레젠테이션"><i class="fa fa-check"></i><b>4.3.2</b> 효과적인 프레젠테이션</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> 데이터 시각화</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#데이터-시각화-1"><i class="fa fa-check"></i><b>5.1</b> 데이터 시각화</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="chapter5.html"><a href="chapter5.html#데이터-시각화의-개념"><i class="fa fa-check"></i><b>5.1.1</b> 데이터 시각화의 개념</a></li>
<li class="chapter" data-level="5.1.2" data-path="chapter5.html"><a href="chapter5.html#데이터-시각화의-목적-및-효과"><i class="fa fa-check"></i><b>5.1.2</b> 데이터 시각화의 목적 및 효과</a></li>
<li class="chapter" data-level="5.1.3" data-path="chapter5.html"><a href="chapter5.html#시각화의-분류와-구분"><i class="fa fa-check"></i><b>5.1.3</b> 시각화의 분류와 구분</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#데이터-시각화-구현"><i class="fa fa-check"></i><b>5.2</b> 데이터 시각화 구현</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="chapter5.html"><a href="chapter5.html#시각화-프로세스"><i class="fa fa-check"></i><b>5.2.1</b> 시각화 프로세스</a></li>
<li class="chapter" data-level="5.2.2" data-path="chapter5.html"><a href="chapter5.html#시각화의-다양한-기법"><i class="fa fa-check"></i><b>5.2.2</b> 시각화의 다양한 기법</a></li>
<li class="chapter" data-level="5.2.3" data-path="chapter5.html"><a href="chapter5.html#시각화-도구"><i class="fa fa-check"></i><b>5.2.3</b> 시각화 도구</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#성공적인-데이터-시각화를-위한-요소"><i class="fa fa-check"></i><b>5.3</b> 성공적인 데이터 시각화를 위한 요소</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="chapter5.html"><a href="chapter5.html#성공적인-데이터-시각화를-위한-요소-1"><i class="fa fa-check"></i><b>5.3.1</b> 성공적인 데이터 시각화를 위한 요소</a></li>
<li class="chapter" data-level="5.3.2" data-path="chapter5.html"><a href="chapter5.html#데이터-시각화의-전망"><i class="fa fa-check"></i><b>5.3.2</b> 데이터 시각화의 전망</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> 데이터 마이닝</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#데이터-과학에서-데이터마이닝의-역할"><i class="fa fa-check"></i><b>6.1</b> 데이터 과학에서 데이터마이닝의 역할</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝의-개념"><i class="fa fa-check"></i><b>6.2</b> 데이터마이닝의 개념</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="chapter6.html"><a href="chapter6.html#데이터미이닝의-정의"><i class="fa fa-check"></i><b>6.2.1</b> 데이터미이닝의 정의</a></li>
<li class="chapter" data-level="6.2.2" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝의-특징"><i class="fa fa-check"></i><b>6.2.2</b> 데이터마이닝의 특징</a></li>
<li class="chapter" data-level="6.2.3" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝의-과정"><i class="fa fa-check"></i><b>6.2.3</b> 데이터마이닝의 과정</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝-관련-분야"><i class="fa fa-check"></i><b>6.3</b> 데이터마이닝 관련 분야</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="chapter6.html"><a href="chapter6.html#고객관계관리"><i class="fa fa-check"></i><b>6.3.1</b> 고객관계관리</a></li>
<li class="chapter" data-level="6.3.2" data-path="chapter6.html"><a href="chapter6.html#신용평가"><i class="fa fa-check"></i><b>6.3.2</b> 신용평가</a></li>
<li class="chapter" data-level="6.3.3" data-path="chapter6.html"><a href="chapter6.html#품질개선"><i class="fa fa-check"></i><b>6.3.3</b> 품질개선</a></li>
<li class="chapter" data-level="6.3.4" data-path="chapter6.html"><a href="chapter6.html#부정행위-적발"><i class="fa fa-check"></i><b>6.3.4</b> 부정행위 적발</a></li>
<li class="chapter" data-level="6.3.5" data-path="chapter6.html"><a href="chapter6.html#이미지-분석"><i class="fa fa-check"></i><b>6.3.5</b> 이미지 분석</a></li>
<li class="chapter" data-level="6.3.6" data-path="chapter6.html"><a href="chapter6.html#생명정보학"><i class="fa fa-check"></i><b>6.3.6</b> 생명정보학</a></li>
<li class="chapter" data-level="6.3.7" data-path="chapter6.html"><a href="chapter6.html#인터넷기업"><i class="fa fa-check"></i><b>6.3.7</b> 인터넷기업</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝-기법-및-도구"><i class="fa fa-check"></i><b>6.4</b> 데이터마이닝 기법 및 도구</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="chapter6.html"><a href="chapter6.html#지도학습과-비지도학습"><i class="fa fa-check"></i><b>6.4.1</b> 지도학습과 비지도학습</a></li>
<li class="chapter" data-level="6.4.2" data-path="chapter6.html"><a href="chapter6.html#분류분석"><i class="fa fa-check"></i><b>6.4.2</b> 분류분석</a></li>
<li class="chapter" data-level="6.4.3" data-path="chapter6.html"><a href="chapter6.html#예측분석"><i class="fa fa-check"></i><b>6.4.3</b> 예측분석</a></li>
<li class="chapter" data-level="6.4.4" data-path="chapter6.html"><a href="chapter6.html#군집분석"><i class="fa fa-check"></i><b>6.4.4</b> 군집분석</a></li>
<li class="chapter" data-level="6.4.5" data-path="chapter6.html"><a href="chapter6.html#연관성-분석"><i class="fa fa-check"></i><b>6.4.5</b> 연관성 분석</a></li>
<li class="chapter" data-level="6.4.6" data-path="chapter6.html"><a href="chapter6.html#텍스트마이닝"><i class="fa fa-check"></i><b>6.4.6</b> 텍스트마이닝</a></li>
<li class="chapter" data-level="6.4.7" data-path="chapter6.html"><a href="chapter6.html#사회연결망분석"><i class="fa fa-check"></i><b>6.4.7</b> 사회연결망분석</a></li>
<li class="chapter" data-level="6.4.8" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝-분석도구"><i class="fa fa-check"></i><b>6.4.8</b> 데이터마이닝 분석도구</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#데이터마이닝-적용-사례"><i class="fa fa-check"></i><b>6.5</b> 데이터마이닝 적용 사례</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="chapter6.html"><a href="chapter6.html#신용카드사의-부정사용자-적발을-위한-데이터마이닝"><i class="fa fa-check"></i><b>6.5.1</b> 신용카드사의 부정사용자 적발을 위한 데이터마이닝</a></li>
<li class="chapter" data-level="6.5.2" data-path="chapter6.html"><a href="chapter6.html#이동통신사-고객이탈방지를-위한-데이터마이닝"><i class="fa fa-check"></i><b>6.5.2</b> 이동통신사 고객이탈방지를 위한 데이터마이닝</a></li>
<li class="chapter" data-level="6.5.3" data-path="chapter6.html"><a href="chapter6.html#dna-칩-자료분석에서의-데이터마이닝"><i class="fa fa-check"></i><b>6.5.3</b> DNA 칩 자료분석에서의 데이터마이닝</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> 데이터 과학자의 역할 및 전망</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#데이터-과학자의-필요역량"><i class="fa fa-check"></i><b>7.1</b> 데이터 과학자의 필요역량</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="chapter7.html"><a href="chapter7.html#기술적-필요역량"><i class="fa fa-check"></i><b>7.1.1</b> 기술적 필요역량</a></li>
<li class="chapter" data-level="7.1.2" data-path="chapter7.html"><a href="chapter7.html#인문학적-소양-및-이해의-중요성"><i class="fa fa-check"></i><b>7.1.2</b> 인문학적 소양 및 이해의 중요성</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#데이터-과학자의-윤리의식"><i class="fa fa-check"></i><b>7.2</b> 데이터 과학자의 윤리의식</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="chapter7.html"><a href="chapter7.html#데이터-과학에서의-위기요인"><i class="fa fa-check"></i><b>7.2.1</b> 데이터 과학에서의 위기요인</a></li>
<li class="chapter" data-level="7.2.2" data-path="chapter7.html"><a href="chapter7.html#데이터-과학자의-윤리"><i class="fa fa-check"></i><b>7.2.2</b> 데이터 과학자의 윤리</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#데이터-과학-및-데이터-과학자의-전망"><i class="fa fa-check"></i><b>7.3</b> 데이터 과학 및 데이터 과학자의 전망</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Big Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter6" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> 데이터 마이닝<a href="chapter6.html#chapter6" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!---------- Chapter 6 데이터 마이닝의 이해-------------------->
<div id="데이터-과학에서-데이터마이닝의-역할" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> 데이터 과학에서 데이터마이닝의 역할<a href="chapter6.html#데이터-과학에서-데이터마이닝의-역할" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>데이터 과학에서 분석과정은 전략적 통찰력을 창출하는 데 핵심적인 역할을 함</p>
<ul>
<li><p>데이터에 내재된 스토리와 가치를 도출하기 위해 데이터 과학에서는 다양한 분석기법을 사용함</p></li>
<li><p>데이터 시각화 기법들은 데이터의 성향 및 변수들의 연관성을 시각적으로 도출한다는 점에서 분석기법의 하나로 정의될 수 있음</p></li>
<li><p>평균, 상관계수 등 기초통계량에 기반한 통계기법 및 데이터베이스 조회(query) 기능을 통해서도 유용한 정보를 찾아낼 수 있음</p></li>
<li><p>리포팅(reporting), OLAP(On-Line Analytical Processing), 기초통계분석 등은 주로 제한된 용량의 데이터를 한번에 다루는 데 사용됨</p></li>
</ul></li>
<li><p>기존의 분석 접근법은 빅데이터시대에 사용하기에는 한계가 있음</p>
<ul>
<li>데이터마이닝은 데이터베이스 또는 데이터웨어하우스에 분산 저장된 방대한 양의 데이터로부터 흥미로운 패턴을 발견하고 미래에 대한 예측모형을 구축하는 작업임</li>
</ul></li>
</ul>
<p><br></p>
</div>
<div id="데이터마이닝의-개념" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> 데이터마이닝의 개념<a href="chapter6.html#데이터마이닝의-개념" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="데이터미이닝의-정의" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> 데이터미이닝의 정의<a href="chapter6.html#데이터미이닝의-정의" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>데이터마이닝은 다량의 가공하지 않은 데이터로부터 소량의 귀중하고 유용한 정보 혹은 지식을 추출하는 과정</p></li>
<li><p>방대한 데이터를 정제하여 통계 및 수학적 기술 그리고 패턴 인식 기술 등을 사용하여 의미있는 연관성, 패턴 그리고 추세를 발견하는 과정을 총칭함</p></li>
<li><p>데이터마이닝과 유사한 용어로서</p>
<ul>
<li>데이터베이스로부터의 지식 마이닝(knowledge mining from database)</li>
<li>지식 추출(knowledge extraction)</li>
<li>데이터/패턴 분석(data/pattern analysis)</li>
<li>데이터 고고학(data archaeology)</li>
<li>데이터 준설(data dredging) 등</li>
</ul></li>
<li><p>데이터마이닝은 컴퓨터과학의 인공지능(artificial intelligence), 로봇비전(robot vision), 패턴 인식 등에 활용되는 기계학습(machine learning) 이론에서부터 시작됨</p></li>
<li><p>데이터마이닝의 주된 사용목적은 데이터 분석 및 예측모형 적합에 있음</p>
<ul>
<li><p>기존의 통계학과 비교하여 방법론적인 측면에서 큰 차이점은 없음</p></li>
<li><p>통계학 분야의 선형회귀(linear regression), 로지스틱회귀(logistic regression), 판별분석(discriminant analysis), 주성분분석(principle component analysis), 군집분석(clustering analysis) 등은 데이터를 탐색하고 모형을 설계하는 방법</p></li>
<li><p>컴퓨터공학에서는 나무모형(tree based model)이나 신경망모형(neural network)과 같은 예측, 분류를 위한 기계학습 기법들을 발전시켜 옴</p></li>
<li><p>기존의 통계학이 특정 변수가 결과에 미치는 영향력을 정량화하는 추론(inference)을 강조하는 반면, 데이터마이닝은 결과에 영향을 주는 변수들의 관계를 모형화하여 이로부터 정확한 예측(prediction)을 하는 데 주목적이 있음</p></li>
</ul></li>
<li><p>데이터마이닝의 분야별 정리</p></li>
</ul>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>분야</th>
<th>정의</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>컴퓨터과학</td>
<td>패턴 인식 기술뿐만 아니라 통계적/수학적 분석방법을 이용하여 저장된 거대한 자료로부터 우리에게 유익하고 흥미 있는 새로운 관계, 성향, 패턴 등 다양하고 가치 있는 정보를 찾아내는 일련의 과정</td>
</tr>
<tr class="even">
<td>경영정보 시스템(MIS)</td>
<td>거대한 데이터베이스 혹은 자료에서 유용한 정보를 추출하는 일련의 과정뿐만 아니라 값진 정보를 사용자가 전문적 지식 없이 사용할 수 있는 의사결정 지원 시스템 개발과정을 통칭</td>
</tr>
<tr class="odd">
<td>통계학</td>
<td>올바른 의사결정을 지원하기 위한 데이터 분석 및 모형 선택 방법론의 개발</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div id="데이터마이닝의-특징" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> 데이터마이닝의 특징<a href="chapter6.html#데이터마이닝의-특징" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>데이터마이닝은 주로 통계학, 컴퓨터과학, 인공지능공학과 같은 분야에서 개발되는 특징이 있음</p></li>
<li><p>실제 활용하는 전문가들은 경영, 경제, 정보기술, 금융공학, 생물정보학 등의 다양한 분야에서 활약하는 데이터 과학자들</p></li>
<li><p>데이터마이닝 기법은 데이터 과학의 분석 단계에서 필수불가결한 도구로 활용되고 있음</p></li>
<li><p>데이터마이닝의 특징</p></li>
</ul>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>특징</th>
<th>비고</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>대용량의 관측 가능한 자료</td>
<td>- 시간의 흐름에 따라 축적됨<br> - 데이터 분석을 업무에 두지 않는 경우가 많음</td>
</tr>
<tr class="even">
<td>컴퓨터 집약적 기법(computer-intensive method)</td>
<td>- 컴퓨터의 강력한 처리속도와 능력 활용<br> - 기존 분석기법의 한계 극복</td>
</tr>
<tr class="odd">
<td>경험적 방법(adhockery method)</td>
<td>- 경험에 기초하여 기법 개발 <br> - 수리적 특성이 규명되지 않는 기법도 존재</td>
</tr>
<tr class="even">
<td>일반화(generalization)</td>
<td>- 새로운 데이터에 얼마나 잘 적용되는지가 성공적인 데이터마이닝 기법의 판단 기준임</td>
</tr>
<tr class="odd">
<td>업무활용성(business applications)</td>
<td>- 다양한 경영 상황하에서 경쟁력 확보를 위한 의사결정을 지원</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div id="데이터마이닝의-과정" class="section level3 hasAnchor" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> 데이터마이닝의 과정<a href="chapter6.html#데이터마이닝의-과정" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>일반적으로 데이터마이닝의 각 단계들은 상호배타적으로 이루어지지 않으며, 한 방향의, 직전석으로 적용되기보다는 상호보완적으로 반복되어 수행됨</p></li>
<li><p>데이터마이닝의 수행 단계</p></li>
</ul>
<center>
<img src="fig6/f1.png" />
</center>
<ol style="list-style-type: decimal">
<li>목적 결정</li>
</ol>
<ul>
<li>프로젝트의 목적을 계획하고 설정하는 단계</li>
<li>많은 경우 계획 단계에서 문제의식이 미리 설정되어 관련 데이터를 수집하게 되지만, 때로는 데이터 수집 후 탐색과정을 거쳐 문제가 설정되기도 함</li>
<li>또는 탐색과정에서 얻은 새로운 발견으로부터 기설정된 목적이 재설정되기도 함</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>데이터 수집</li>
</ol>
<ul>
<li>데이터는 대부분 데이터베이스에서 무작위로 추출하거나 전부 추출하지만, 때로는 분산된 데이터베이스에서 따로 추출하여 통합하기도 함</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>데이터 탐색 및 정제</li>
</ol>
<ul>
<li>본격적인 데이터마이닝 기법을 적용하기 위해 데이터를 표준화하고 점검(quality control)하는 단계</li>
<li>데이터에 결측값(missing value)이 존재하는지, 모든 값은 상식적인 범위 내에 있는지, 이상값은 존재하는지 등의 여부를 조사하여 분석에 적합하도록 처리함</li>
<li>탐색과정에서 그래프를 이용한 시각화나 탐색적 자료분석의 기법이 효과적으로 활용됨</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>데이터마이닝 방법 결정</li>
</ol>
<ul>
<li>데이터마이닝 문제(분류, 예측, 군집화 등)와 데이터마이닝 기법(로지스틱회귀, 신경망, 계층군집 등)을 선택하는 단계</li>
<li>일반적인 문제(단계1)를 구체적인 통계 문제로 전환하여 수리적 접근을 함</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>모형 선택</li>
</ol>
<ul>
<li>데이터마이닝 프로세스의 여러 단계를 반복적으로 수행하여 가장 좋은 모형을 찾는 단계</li>
<li>일반적으로 검정데이터(test data)를 이용하여 가장 좋은 성능을 내는 모형의 파라미터를 결정</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>성능평가</li>
</ol>
<ul>
<li>검증데이터를 이용하여 구죽된 모형의 성능을 평가하여 가장 효율적인 모형을 찾는 단계</li>
<li>예측문제의 경우, 다양한 데이터마이닝 기법들 중 예측력이 가장 우수한 것을 선택하여 최종 모형으로 선정</li>
</ul>
<ol start="7" style="list-style-type: decimal">
<li>적용</li>
</ol>
<ul>
<li>구축된 모형을 운용 시스템에 탑재하여 실제 의사결정에 적용하는 단계</li>
<li>예를 들어, 구축된 모형을 적용하여 구매 가능성이 높은 고객을 결정하고 해당 고객에게 구매 권유 메일을 보내어 수익 창출 가능성을 높임</li>
</ul>
<p><br></p>
</div>
</div>
<div id="데이터마이닝-관련-분야" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> 데이터마이닝 관련 분야<a href="chapter6.html#데이터마이닝-관련-분야" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>데이터마이닝은 관련된 분야가 다양하고, 데이터마이닝 기법은 범용 방법론을 제공하고 있으므로 활용분야도 매우 다양하고 제한이 없음</li>
</ul>
<p><br></p>
<div id="고객관계관리" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> 고객관계관리<a href="chapter6.html#고객관계관리" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>데이터베이스의 정보를 이용한 마케팅 중 하나인 고개관계관리(Customer Relationship Management, CRM)는 소매, 통신판매, 금융서비스, 건강, 보험, 통신, 운송, 제약 등 다양한 분야에서 활발하게 진행되고 있음</p></li>
<li><p>고객관계관리의 세부 분야인 목표 마케팅(target marketing), 고객 세분화(segmentation), 고객성향 변동분석(churn analysis), 교차판매(cross selling), 장바구니분석(market basket analysis) 등에 데이터마이닝 기법이 중요한 역할을 함</p></li>
</ul>
<p><br></p>
</div>
<div id="신용평가" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> 신용평가<a href="chapter6.html#신용평가" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>신용평가는 특정인의 신용거래 대출한도를 결정하는 것이 주업무로, 목적은 불량채권과 대손을 추정하여 이를 최소화함
<ul>
<li>신용거래 확대를 위한 의사결정 적용분야로 신용카드, 주택할부금용, 소비자대출, 상업대출 등이 있음</li>
<li>신용평가의 중요한 사안은 현재의 대출한도액을 유지, 관리하면서 불량채권에 대한 최선의 대응책을 마련</li>
</ul></li>
<li>신용관리는 은행, 금융서비스, 저당권보험(담보부 보험), 소매(할부 판매) 등 다양한 분야에 적용됨</li>
</ul>
<p><br></p>
</div>
<div id="품질개선" class="section level3 hasAnchor" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> 품질개선<a href="chapter6.html#품질개선" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>불량품을 찾고, 그 원인을 밝혀서 이를 궁극적으로 예방하는 것</p></li>
<li><p>병원과 의료보험조합 등에서는 병원에서 발생하는 사망, 불필요한 장기입원 및 의료비 과다청구에 초점을 맞추고 있으며, 제조업체에서는 제품보증청구를 유발하는 불량품 감소를 통한 이윤증가에 중점을 둠</p></li>
</ul>
<p><br></p>
</div>
<div id="부정행위-적발" class="section level3 hasAnchor" number="6.3.4">
<h3><span class="header-section-number">6.3.4</span> 부정행위 적발<a href="chapter6.html#부정행위-적발" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>부정행위 적발의 목적은 고도의 사기행위를 발견할 수 있는 패턴을 알아내는 것</p></li>
<li><p>은행에서는 신용카드 거래사기 및 불량수표를 적발할 수 있고, 보험회사에서는 보험금의 허위, 과다청구를 예방하며, 통신회사에서는 스미싱 문자 전송을 자동 식별하기 위해 데이터마이닝을 활용함</p></li>
</ul>
<p><br></p>
</div>
<div id="이미지-분석" class="section level3 hasAnchor" number="6.3.5">
<h3><span class="header-section-number">6.3.5</span> 이미지 분석<a href="chapter6.html#이미지-분석" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>이미지 분석은 디지털화된 사진으로부터 패턴을 추출하는 기법</p></li>
<li><p>천문학, 문자인식, 의료진단, 방위산업 등 다양한 분야에서 활용</p></li>
</ul>
<p><br></p>
</div>
<div id="생명정보학" class="section level3 hasAnchor" number="6.3.6">
<h3><span class="header-section-number">6.3.6</span> 생명정보학<a href="chapter6.html#생명정보학" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>대량으로 쏟아지는 유전자 서열 데이터를 분석해 유전체 각 부분의 기능을 판단하고 예측함</li>
</ul>
<p><br></p>
</div>
<div id="인터넷기업" class="section level3 hasAnchor" number="6.3.7">
<h3><span class="header-section-number">6.3.7</span> 인터넷기업<a href="chapter6.html#인터넷기업" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>최근 성공을 거두고 있는 인터넷기업들의 중요한 성공요소로서 적극적인 데이터마이닝 기법의 활용을 들 수 있음</li>
<li>예를 들어, 링크드인(LinkedIn)의 ’당신이 알 수도 있는 사람들(People You May Know)’과 같은 서비스는 새로운 수백만 페이지뷰를 창출해 냈고, 이 기능으로 단숨에 더 높은 단계로 도약함</li>
<li>아마존(Amazon)은 고객의 과거 구매 기록에 근거해 같은 상품을 구매한 고객들이 주로 구매한 상품을 제시하는 추천 시스템(recommendation system)을 도입하여 높은 매출을 올리고 있음</li>
</ul>
<p><br></p>
</div>
</div>
<div id="데이터마이닝-기법-및-도구" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> 데이터마이닝 기법 및 도구<a href="chapter6.html#데이터마이닝-기법-및-도구" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="지도학습과-비지도학습" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> 지도학습과 비지도학습<a href="chapter6.html#지도학습과-비지도학습" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>데이터마이닝 기법은 크게 지도학습(supervised learning)과 비지도학습(unsupervised learning)으로 나눌 수 있음</p></li>
<li><p>지도학습의 목표는 입출력 간의 관계를 결정하는 시스템에 대한 유용한 근사 시스템을 구하는 것으로 정의할 수 있음</p>
<ul>
<li>입력정보를 담고 있는 변수를 입력변수(input variable) 혹은 설명변수(explanatory variable)라 하고, 출력정보는 출력변수(output variable) 혹은 반응변수(response variable)라고 함</li>
</ul></li>
<li><p>지도학습에서는 학습에 사용되는 실제 출력변수가 존재하여 입출력 변수 간의 관계를 근사시키는 모형 또는 규칙을 학습함</p>
<ul>
<li><p>입출력 변수 간의 관계가 모형으로부터 설정되면 데이터로부터 가상(artificial) 출력값을 생성할 수 있고, 이 값이 실제 출력변수값과 유사한 값을 예측하는 모형 및 관계를 구축하는 방식으로 학습이 이루어짐</p></li>
<li><p>대부분의 분류(classification) 문제와 예측(prediction) 문제는 지도학습에 속함</p></li>
</ul></li>
<li><p>비지도학습은 실제 출력변수가 명시적으로 존재하지 않는 학습법</p>
<ul>
<li>출력값이 존재하지 않기 때문에 데이터에 존재하는 여러 가지 형태의 특징을 추출하는 데 목적을 둠</li>
<li>생명정보학의 마이크로어레이 데이터 분석에서와 같이 데이터 중에서 유사한 특성을 가지는 그룹의 존재를 찾는 문제</li>
<li>장바구니분석에서와 같이 특정한 특성의 존재가 다른 특성의 존재를 설명하는지를 찾는 문제 등</li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li>사용목적에 따른 데이터마이닝 기법 분류</li>
</ul>
<ol style="list-style-type: decimal">
<li>지도학습(supervised learning)</li>
</ol>
<ul>
<li>분류분석(classification analysis)
<ul>
<li>판별분석(discriminant analysis)</li>
<li>로지스틱 회귀분석(logistic regression)</li>
<li>최근접이웃기법(K-nearest neighbor)</li>
<li>의사결정나무(decision tree)</li>
<li>나이브베이즈 분류(naive Bayes)</li>
<li>신경망(neural network)</li>
<li>지도벡터기계(support vector machines)</li>
</ul></li>
<li>예측분석(prediction analysis)
<ul>
<li>회귀분석(regression analysis)</li>
<li>최근접이웃기법(K-nearest neighbor)</li>
<li>신경망(neural network)</li>
<li>평활법(smoothing)</li>
</ul></li>
</ul>
<p><br></p>
<ol start="2" style="list-style-type: decimal">
<li>비지도학습(unsupervised learning)</li>
</ol>
<ul>
<li>군집분석(clustering analysis)
<ul>
<li>K-평균(k-means)</li>
<li>계층적 군집분석(hierarchical clustering)</li>
<li>유한혼합모형(finite mixture model)</li>
<li>이중군집법(Biclustering)</li>
</ul></li>
<li>연관분석(association anlaysis)
<ul>
<li>장바구니분석(market basket analysis)</li>
<li>서열분석(sequence analysis)</li>
<li>트랜잭션 데이터 분석(Transaction data analysis)</li>
</ul></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>비정형분석</li>
</ol>
<ul>
<li>텍스트마이닝(text mining)</li>
<li>사회연결망분석(Social network analysis)</li>
</ul>
<p><br></p>
</div>
<div id="분류분석" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> 분류분석<a href="chapter6.html#분류분석" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>분류분석(classification analysis)은 데이터의 실체가 어떤 그룹에 속하는지 예측하는 데 사용하는 데이터마이닝 기법</p>
<ul>
<li>분류(classification)는 객체를 정해 놓은 범주로 분류하는 데 목적이 있음</li>
<li>분류분석은 각 자료의 분류 라벨(label)이 출력변수 역할을 하므로 지도학습으로 분류됨</li>
</ul></li>
</ul>
<div id="discriminant-analysis" class="section level4 unnumbered hasAnchor">
<h4>Discriminant analysis<a href="chapter6.html#discriminant-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f2.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="chapter6.html#cb1-1" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb1-2"><a href="chapter6.html#cb1-2" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb1-3"><a href="chapter6.html#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="chapter6.html#cb1-4" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb1-5"><a href="chapter6.html#cb1-5" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb1-6"><a href="chapter6.html#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="chapter6.html#cb1-7" tabindex="-1"></a><span class="co"># Perform Linear Discriminant Analysis</span></span>
<span id="cb1-8"><a href="chapter6.html#cb1-8" tabindex="-1"></a>lda_model <span class="ot">&lt;-</span> <span class="fu">lda</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> iris)</span>
<span id="cb1-9"><a href="chapter6.html#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="chapter6.html#cb1-10" tabindex="-1"></a><span class="co"># Display the model results</span></span>
<span id="cb1-11"><a href="chapter6.html#cb1-11" tabindex="-1"></a><span class="fu">print</span>(lda_model)</span></code></pre></div>
<pre><code>## Call:
## lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, 
##     data = iris)
## 
## Prior probabilities of groups:
##     setosa versicolor  virginica 
##  0.3333333  0.3333333  0.3333333 
## 
## Group means:
##            Sepal.Length Sepal.Width Petal.Length Petal.Width
## setosa            5.006       3.428        1.462       0.246
## versicolor        5.936       2.770        4.260       1.326
## virginica         6.588       2.974        5.552       2.026
## 
## Coefficients of linear discriminants:
##                     LD1         LD2
## Sepal.Length  0.8293776 -0.02410215
## Sepal.Width   1.5344731 -2.16452123
## Petal.Length -2.2012117  0.93192121
## Petal.Width  -2.8104603 -2.83918785
## 
## Proportion of trace:
##    LD1    LD2 
## 0.9912 0.0088</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="chapter6.html#cb3-1" tabindex="-1"></a><span class="co"># Make predictions using the model</span></span>
<span id="cb3-2"><a href="chapter6.html#cb3-2" tabindex="-1"></a>lda_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(lda_model)</span>
<span id="cb3-3"><a href="chapter6.html#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="chapter6.html#cb3-4" tabindex="-1"></a><span class="co"># View the predictions</span></span>
<span id="cb3-5"><a href="chapter6.html#cb3-5" tabindex="-1"></a><span class="fu">head</span>(lda_predictions<span class="sc">$</span>class)</span></code></pre></div>
<pre><code>## [1] setosa setosa setosa setosa setosa setosa
## Levels: setosa versicolor virginica</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="chapter6.html#cb5-1" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb5-2"><a href="chapter6.html#cb5-2" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Predicted =</span> lda_predictions<span class="sc">$</span>class, <span class="at">Actual =</span> iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>##             Actual
## Predicted    setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         48         1
##   virginica       0          2        49</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="chapter6.html#cb7-1" tabindex="-1"></a><span class="co"># Plot the first and second linear discriminants</span></span>
<span id="cb7-2"><a href="chapter6.html#cb7-2" tabindex="-1"></a><span class="fu">plot</span>(lda_predictions<span class="sc">$</span>x[, <span class="dv">1</span>], lda_predictions<span class="sc">$</span>x[, <span class="dv">2</span>], <span class="at">col =</span> iris<span class="sc">$</span>Species, </span>
<span id="cb7-3"><a href="chapter6.html#cb7-3" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;LD1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;LD2&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">main =</span> <span class="st">&quot;LDA of Iris Dataset&quot;</span>)</span>
<span id="cb7-4"><a href="chapter6.html#cb7-4" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">levels</span>(iris<span class="sc">$</span>Species), <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/lda-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="logistic-regression" class="section level4 unnumbered hasAnchor">
<h4>Logistic regression<a href="chapter6.html#logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f3.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="chapter6.html#cb8-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb8-2"><a href="chapter6.html#cb8-2" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb8-3"><a href="chapter6.html#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="chapter6.html#cb8-4" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb8-5"><a href="chapter6.html#cb8-5" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb8-6"><a href="chapter6.html#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="chapter6.html#cb8-7" tabindex="-1"></a><span class="co"># Perform multinomial logistic regression</span></span>
<span id="cb8-8"><a href="chapter6.html#cb8-8" tabindex="-1"></a>logit_model <span class="ot">&lt;-</span> <span class="fu">multinom</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> iris)</span></code></pre></div>
<pre><code>## # weights:  18 (10 variable)
## initial  value 164.791843 
## iter  10 value 16.177348
## iter  20 value 7.111438
## iter  30 value 6.182999
## iter  40 value 5.984028
## iter  50 value 5.961278
## iter  60 value 5.954900
## iter  70 value 5.951851
## iter  80 value 5.950343
## iter  90 value 5.949904
## iter 100 value 5.949867
## final  value 5.949867 
## stopped after 100 iterations</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="chapter6.html#cb10-1" tabindex="-1"></a><span class="co"># Display the model results</span></span>
<span id="cb10-2"><a href="chapter6.html#cb10-2" tabindex="-1"></a><span class="fu">summary</span>(logit_model)</span></code></pre></div>
<pre><code>## Call:
## multinom(formula = Species ~ Sepal.Length + Sepal.Width + Petal.Length + 
##     Petal.Width, data = iris)
## 
## Coefficients:
##            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width
## versicolor    18.69037    -5.458424   -8.707401     14.24477   -3.097684
## virginica    -23.83628    -7.923634  -15.370769     23.65978   15.135301
## 
## Std. Errors:
##            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width
## versicolor    34.97116     89.89215    157.0415     60.19170    45.48852
## virginica     35.76649     89.91153    157.1196     60.46753    45.93406
## 
## Residual Deviance: 11.89973 
## AIC: 31.89973</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="chapter6.html#cb12-1" tabindex="-1"></a><span class="co"># Make predictions using the model</span></span>
<span id="cb12-2"><a href="chapter6.html#cb12-2" tabindex="-1"></a>logit_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(logit_model, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb12-3"><a href="chapter6.html#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="chapter6.html#cb12-4" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb12-5"><a href="chapter6.html#cb12-5" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Predicted =</span> logit_predictions, <span class="at">Actual =</span> iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>##             Actual
## Predicted    setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         49         1
##   virginica       0          1        49</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="chapter6.html#cb14-1" tabindex="-1"></a><span class="co"># Visualize the predicted probabilities for the first few observations</span></span>
<span id="cb14-2"><a href="chapter6.html#cb14-2" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(logit_model, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>))</span></code></pre></div>
<pre><code>##      setosa   versicolor    virginica
## 1 1.0000000 1.526406e-09 2.716417e-36
## 2 0.9999996 3.536476e-07 2.883729e-32
## 3 1.0000000 4.443506e-08 6.103424e-34
## 4 0.9999968 3.163905e-06 7.117010e-31
## 5 1.0000000 1.102983e-09 1.289946e-36
## 6 1.0000000 3.521573e-10 1.344907e-35</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="chapter6.html#cb16-1" tabindex="-1"></a><span class="co"># Get predicted probabilities for each class</span></span>
<span id="cb16-2"><a href="chapter6.html#cb16-2" tabindex="-1"></a>predicted_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(logit_model, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb16-3"><a href="chapter6.html#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="chapter6.html#cb16-4" tabindex="-1"></a><span class="co"># Add the predicted probabilities as columns to the iris dataset</span></span>
<span id="cb16-5"><a href="chapter6.html#cb16-5" tabindex="-1"></a>iris_with_probs <span class="ot">&lt;-</span> <span class="fu">cbind</span>(iris, predicted_probs)</span>
<span id="cb16-6"><a href="chapter6.html#cb16-6" tabindex="-1"></a></span>
<span id="cb16-7"><a href="chapter6.html#cb16-7" tabindex="-1"></a><span class="co"># Melt the dataset for easier plotting</span></span>
<span id="cb16-8"><a href="chapter6.html#cb16-8" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb16-9"><a href="chapter6.html#cb16-9" tabindex="-1"></a><span class="fu">library</span>(reshape2)</span>
<span id="cb16-10"><a href="chapter6.html#cb16-10" tabindex="-1"></a>iris_melted <span class="ot">&lt;-</span> <span class="fu">melt</span>(iris_with_probs, <span class="at">id.vars =</span> <span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>, <span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>, <span class="st">&quot;Species&quot;</span>), </span>
<span id="cb16-11"><a href="chapter6.html#cb16-11" tabindex="-1"></a>                    <span class="at">variable.name =</span> <span class="st">&quot;Predicted_Species&quot;</span>, <span class="at">value.name =</span> <span class="st">&quot;Probability&quot;</span>)</span>
<span id="cb16-12"><a href="chapter6.html#cb16-12" tabindex="-1"></a></span>
<span id="cb16-13"><a href="chapter6.html#cb16-13" tabindex="-1"></a><span class="co"># Plot the predicted probabilities using ggplot2</span></span>
<span id="cb16-14"><a href="chapter6.html#cb16-14" tabindex="-1"></a><span class="fu">ggplot</span>(iris_melted, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Predicted_Species, <span class="at">size =</span> Probability)) <span class="sc">+</span></span>
<span id="cb16-15"><a href="chapter6.html#cb16-15" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb16-16"><a href="chapter6.html#cb16-16" tabindex="-1"></a>  <span class="fu">scale_size_continuous</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">8</span>)) <span class="sc">+</span></span>
<span id="cb16-17"><a href="chapter6.html#cb16-17" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Predicted Probabilities of Iris Species&quot;</span>,</span>
<span id="cb16-18"><a href="chapter6.html#cb16-18" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb16-19"><a href="chapter6.html#cb16-19" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb16-20"><a href="chapter6.html#cb16-20" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/logistic-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="k-nearest-neighbor" class="section level4 unnumbered hasAnchor">
<h4>K-nearest neighbor<a href="chapter6.html#k-nearest-neighbor" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f4.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="chapter6.html#cb17-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb17-2"><a href="chapter6.html#cb17-2" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb17-3"><a href="chapter6.html#cb17-3" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb17-4"><a href="chapter6.html#cb17-4" tabindex="-1"></a></span>
<span id="cb17-5"><a href="chapter6.html#cb17-5" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb17-6"><a href="chapter6.html#cb17-6" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb17-7"><a href="chapter6.html#cb17-7" tabindex="-1"></a></span>
<span id="cb17-8"><a href="chapter6.html#cb17-8" tabindex="-1"></a><span class="co"># Set the number of neighbors (k)</span></span>
<span id="cb17-9"><a href="chapter6.html#cb17-9" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb17-10"><a href="chapter6.html#cb17-10" tabindex="-1"></a></span>
<span id="cb17-11"><a href="chapter6.html#cb17-11" tabindex="-1"></a><span class="co"># Prepare the data: We use the first four columns (features) for KNN</span></span>
<span id="cb17-12"><a href="chapter6.html#cb17-12" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> iris[, <span class="sc">-</span><span class="dv">5</span>]  <span class="co"># Exclude the &#39;Species&#39; column (target)</span></span>
<span id="cb17-13"><a href="chapter6.html#cb17-13" tabindex="-1"></a>train_labels <span class="ot">&lt;-</span> iris<span class="sc">$</span>Species  <span class="co"># &#39;Species&#39; is the target variable</span></span>
<span id="cb17-14"><a href="chapter6.html#cb17-14" tabindex="-1"></a></span>
<span id="cb17-15"><a href="chapter6.html#cb17-15" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (70% train, 30% test)</span></span>
<span id="cb17-16"><a href="chapter6.html#cb17-16" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># Set seed for reproducibility</span></span>
<span id="cb17-17"><a href="chapter6.html#cb17-17" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(train_labels, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb17-18"><a href="chapter6.html#cb17-18" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> train_data[train_index, ]</span>
<span id="cb17-19"><a href="chapter6.html#cb17-19" tabindex="-1"></a>train_labels <span class="ot">&lt;-</span> train_labels[train_index]</span>
<span id="cb17-20"><a href="chapter6.html#cb17-20" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> train_data[<span class="sc">-</span>train_index, ]</span>
<span id="cb17-21"><a href="chapter6.html#cb17-21" tabindex="-1"></a>test_labels <span class="ot">&lt;-</span> train_labels[<span class="sc">-</span>train_index]</span>
<span id="cb17-22"><a href="chapter6.html#cb17-22" tabindex="-1"></a></span>
<span id="cb17-23"><a href="chapter6.html#cb17-23" tabindex="-1"></a><span class="co"># Perform KNN classification</span></span>
<span id="cb17-24"><a href="chapter6.html#cb17-24" tabindex="-1"></a>knn_predictions <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_data, <span class="at">test =</span> test_data, <span class="at">cl =</span> train_labels, <span class="at">k =</span> k)</span>
<span id="cb17-25"><a href="chapter6.html#cb17-25" tabindex="-1"></a></span>
<span id="cb17-26"><a href="chapter6.html#cb17-26" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb17-27"><a href="chapter6.html#cb17-27" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(knn_predictions, test_labels)</span>
<span id="cb17-28"><a href="chapter6.html#cb17-28" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0          9         0
##   virginica       0          0        12
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.8878, 1)
##     No Information Rate : 0.3871     
##     P-Value [Acc &gt; NIR] : 1.669e-13  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           1.0000
## Specificity                 1.0000            1.0000           1.0000
## Pos Pred Value              1.0000            1.0000           1.0000
## Neg Pred Value              1.0000            1.0000           1.0000
## Prevalence                  0.3226            0.2903           0.3871
## Detection Rate              0.3226            0.2903           0.3871
## Detection Prevalence        0.3226            0.2903           0.3871
## Balanced Accuracy           1.0000            1.0000           1.0000</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="chapter6.html#cb19-1" tabindex="-1"></a><span class="co"># Add the predictions to the test data for visualization</span></span>
<span id="cb19-2"><a href="chapter6.html#cb19-2" tabindex="-1"></a>test_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(test_data, <span class="at">Actual =</span> test_labels, <span class="at">Predicted =</span> knn_predictions)</span>
<span id="cb19-3"><a href="chapter6.html#cb19-3" tabindex="-1"></a></span>
<span id="cb19-4"><a href="chapter6.html#cb19-4" tabindex="-1"></a><span class="co"># Plot the results using ggplot2</span></span>
<span id="cb19-5"><a href="chapter6.html#cb19-5" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb19-6"><a href="chapter6.html#cb19-6" tabindex="-1"></a><span class="fu">ggplot</span>(test_results, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb19-7"><a href="chapter6.html#cb19-7" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb19-8"><a href="chapter6.html#cb19-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">&quot;KNN Classification (k =&quot;</span>, k, <span class="st">&quot;) on Iris Dataset&quot;</span>),</span>
<span id="cb19-9"><a href="chapter6.html#cb19-9" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb19-10"><a href="chapter6.html#cb19-10" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-11"><a href="chapter6.html#cb19-11" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/knn-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="decision-tree" class="section level4 unnumbered hasAnchor">
<h4>Decision tree<a href="chapter6.html#decision-tree" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f5.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="chapter6.html#cb20-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb20-2"><a href="chapter6.html#cb20-2" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb20-3"><a href="chapter6.html#cb20-3" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb20-4"><a href="chapter6.html#cb20-4" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb20-5"><a href="chapter6.html#cb20-5" tabindex="-1"></a></span>
<span id="cb20-6"><a href="chapter6.html#cb20-6" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb20-7"><a href="chapter6.html#cb20-7" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb20-8"><a href="chapter6.html#cb20-8" tabindex="-1"></a></span>
<span id="cb20-9"><a href="chapter6.html#cb20-9" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb20-10"><a href="chapter6.html#cb20-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb20-11"><a href="chapter6.html#cb20-11" tabindex="-1"></a></span>
<span id="cb20-12"><a href="chapter6.html#cb20-12" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (70% train, 30% test)</span></span>
<span id="cb20-13"><a href="chapter6.html#cb20-13" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(iris<span class="sc">$</span>Species, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb20-14"><a href="chapter6.html#cb20-14" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> iris[train_index, ]</span>
<span id="cb20-15"><a href="chapter6.html#cb20-15" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> iris[<span class="sc">-</span>train_index, ]</span>
<span id="cb20-16"><a href="chapter6.html#cb20-16" tabindex="-1"></a></span>
<span id="cb20-17"><a href="chapter6.html#cb20-17" tabindex="-1"></a><span class="co"># Build a Decision Tree model</span></span>
<span id="cb20-18"><a href="chapter6.html#cb20-18" tabindex="-1"></a>dt_model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb20-19"><a href="chapter6.html#cb20-19" tabindex="-1"></a></span>
<span id="cb20-20"><a href="chapter6.html#cb20-20" tabindex="-1"></a><span class="co"># Print the Decision Tree model summary</span></span>
<span id="cb20-21"><a href="chapter6.html#cb20-21" tabindex="-1"></a><span class="fu">summary</span>(dt_model)</span></code></pre></div>
<pre><code>## Call:
## rpart(formula = Species ~ Sepal.Length + Sepal.Width + Petal.Length + 
##     Petal.Width, data = train_data, method = &quot;class&quot;)
##   n= 105 
## 
##          CP nsplit  rel error    xerror       xstd
## 1 0.5000000      0 1.00000000 1.2714286 0.05260927
## 2 0.4571429      1 0.50000000 0.7571429 0.07318919
## 3 0.0100000      2 0.04285714 0.1000000 0.03651484
## 
## Variable importance
##  Petal.Width Petal.Length Sepal.Length  Sepal.Width 
##           34           31           22           13 
## 
## Node number 1: 105 observations,    complexity param=0.5
##   predicted class=setosa      expected loss=0.6666667  P(node) =1
##     class counts:    35    35    35
##    probabilities: 0.333 0.333 0.333 
##   left son=2 (35 obs) right son=3 (70 obs)
##   Primary splits:
##       Petal.Length &lt; 2.6  to the left,  improve=35.00000, (0 missing)
##       Petal.Width  &lt; 0.75 to the left,  improve=35.00000, (0 missing)
##       Sepal.Length &lt; 5.55 to the left,  improve=25.76198, (0 missing)
##       Sepal.Width  &lt; 3.05 to the right, improve=12.81365, (0 missing)
##   Surrogate splits:
##       Petal.Width  &lt; 0.75 to the left,  agree=1.000, adj=1.000, (0 split)
##       Sepal.Length &lt; 5.45 to the left,  agree=0.933, adj=0.800, (0 split)
##       Sepal.Width  &lt; 3.35 to the right, agree=0.819, adj=0.457, (0 split)
## 
## Node number 2: 35 observations
##   predicted class=setosa      expected loss=0  P(node) =0.3333333
##     class counts:    35     0     0
##    probabilities: 1.000 0.000 0.000 
## 
## Node number 3: 70 observations,    complexity param=0.4571429
##   predicted class=versicolor  expected loss=0.5  P(node) =0.6666667
##     class counts:     0    35    35
##    probabilities: 0.000 0.500 0.500 
##   left son=6 (36 obs) right son=7 (34 obs)
##   Primary splits:
##       Petal.Width  &lt; 1.65 to the left,  improve=29.281050, (0 missing)
##       Petal.Length &lt; 4.85 to the left,  improve=27.457140, (0 missing)
##       Sepal.Length &lt; 6.65 to the left,  improve= 9.829932, (0 missing)
##       Sepal.Width  &lt; 2.95 to the left,  improve= 2.344913, (0 missing)
##   Surrogate splits:
##       Petal.Length &lt; 4.75 to the left,  agree=0.914, adj=0.824, (0 split)
##       Sepal.Length &lt; 6.35 to the left,  agree=0.729, adj=0.441, (0 split)
##       Sepal.Width  &lt; 2.95 to the left,  agree=0.643, adj=0.265, (0 split)
## 
## Node number 6: 36 observations
##   predicted class=versicolor  expected loss=0.05555556  P(node) =0.3428571
##     class counts:     0    34     2
##    probabilities: 0.000 0.944 0.056 
## 
## Node number 7: 34 observations
##   predicted class=virginica   expected loss=0.02941176  P(node) =0.3238095
##     class counts:     0     1    33
##    probabilities: 0.000 0.029 0.971</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="chapter6.html#cb22-1" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb22-2"><a href="chapter6.html#cb22-2" tabindex="-1"></a>dt_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(dt_model, test_data, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb22-3"><a href="chapter6.html#cb22-3" tabindex="-1"></a></span>
<span id="cb22-4"><a href="chapter6.html#cb22-4" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb22-5"><a href="chapter6.html#cb22-5" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(dt_predictions, test_data<span class="sc">$</span>Species)</span>
<span id="cb22-6"><a href="chapter6.html#cb22-6" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         14         2
##   virginica       0          1        13
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9333         
##                  95% CI : (0.8173, 0.986)
##     No Information Rate : 0.3333         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9            
##                                          
##  Mcnemar&#39;s Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            0.9333           0.8667
## Specificity                 1.0000            0.9333           0.9667
## Pos Pred Value              1.0000            0.8750           0.9286
## Neg Pred Value              1.0000            0.9655           0.9355
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3111           0.2889
## Detection Prevalence        0.3333            0.3556           0.3111
## Balanced Accuracy           1.0000            0.9333           0.9167</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="chapter6.html#cb24-1" tabindex="-1"></a><span class="co"># Visualize the Decision Tree</span></span>
<span id="cb24-2"><a href="chapter6.html#cb24-2" tabindex="-1"></a><span class="fu">rpart.plot</span>(dt_model, <span class="at">main =</span> <span class="st">&quot;Decision Tree for Iris Dataset&quot;</span>, <span class="at">extra =</span> <span class="dv">104</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/tree-1.png" width="672" /></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="chapter6.html#cb25-1" tabindex="-1"></a><span class="co"># Plotting the prediction results using ggplot2</span></span>
<span id="cb25-2"><a href="chapter6.html#cb25-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb25-3"><a href="chapter6.html#cb25-3" tabindex="-1"></a>test_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(test_data, <span class="at">Predicted =</span> dt_predictions)</span>
<span id="cb25-4"><a href="chapter6.html#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="chapter6.html#cb25-5" tabindex="-1"></a><span class="fu">ggplot</span>(test_results, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb25-6"><a href="chapter6.html#cb25-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb25-7"><a href="chapter6.html#cb25-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Decision Tree Classification on Iris Dataset&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb25-8"><a href="chapter6.html#cb25-8" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb25-9"><a href="chapter6.html#cb25-9" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/tree-2.png" width="672" /></p>
<p><br></p>
</div>
<div id="naive-bayes" class="section level4 unnumbered hasAnchor">
<h4>Naive Bayes<a href="chapter6.html#naive-bayes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f6.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="chapter6.html#cb26-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb26-2"><a href="chapter6.html#cb26-2" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb26-3"><a href="chapter6.html#cb26-3" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb26-4"><a href="chapter6.html#cb26-4" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb26-5"><a href="chapter6.html#cb26-5" tabindex="-1"></a></span>
<span id="cb26-6"><a href="chapter6.html#cb26-6" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb26-7"><a href="chapter6.html#cb26-7" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb26-8"><a href="chapter6.html#cb26-8" tabindex="-1"></a></span>
<span id="cb26-9"><a href="chapter6.html#cb26-9" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb26-10"><a href="chapter6.html#cb26-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb26-11"><a href="chapter6.html#cb26-11" tabindex="-1"></a></span>
<span id="cb26-12"><a href="chapter6.html#cb26-12" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (70% train, 30% test)</span></span>
<span id="cb26-13"><a href="chapter6.html#cb26-13" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(iris<span class="sc">$</span>Species, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb26-14"><a href="chapter6.html#cb26-14" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> iris[train_index, ]</span>
<span id="cb26-15"><a href="chapter6.html#cb26-15" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> iris[<span class="sc">-</span>train_index, ]</span>
<span id="cb26-16"><a href="chapter6.html#cb26-16" tabindex="-1"></a></span>
<span id="cb26-17"><a href="chapter6.html#cb26-17" tabindex="-1"></a><span class="co"># Build a Naive Bayes model</span></span>
<span id="cb26-18"><a href="chapter6.html#cb26-18" tabindex="-1"></a>nb_model <span class="ot">&lt;-</span> <span class="fu">naiveBayes</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> train_data)</span>
<span id="cb26-19"><a href="chapter6.html#cb26-19" tabindex="-1"></a></span>
<span id="cb26-20"><a href="chapter6.html#cb26-20" tabindex="-1"></a><span class="co"># Print the Naive Bayes model summary</span></span>
<span id="cb26-21"><a href="chapter6.html#cb26-21" tabindex="-1"></a><span class="fu">print</span>(nb_model)</span></code></pre></div>
<pre><code>## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##     setosa versicolor  virginica 
##  0.3333333  0.3333333  0.3333333 
## 
## Conditional probabilities:
##             Sepal.Length
## Y                [,1]      [,2]
##   setosa     4.991429 0.3657156
##   versicolor 5.942857 0.4558674
##   virginica  6.631429 0.6846087
## 
##             Sepal.Width
## Y                [,1]      [,2]
##   setosa     3.365714 0.3455114
##   versicolor 2.777143 0.3227508
##   virginica  2.982857 0.3222035
## 
##             Petal.Length
## Y                [,1]      [,2]
##   setosa     1.471429 0.1808012
##   versicolor 4.262857 0.4222389
##   virginica  5.591429 0.5741344
## 
##             Petal.Width
## Y                 [,1]       [,2]
##   setosa     0.2314286 0.09321521
##   versicolor 1.3285714 0.20518489
##   virginica  2.0342857 0.25775371</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="chapter6.html#cb28-1" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb28-2"><a href="chapter6.html#cb28-2" tabindex="-1"></a>nb_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(nb_model, test_data)</span>
<span id="cb28-3"><a href="chapter6.html#cb28-3" tabindex="-1"></a></span>
<span id="cb28-4"><a href="chapter6.html#cb28-4" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb28-5"><a href="chapter6.html#cb28-5" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(nb_predictions, test_data<span class="sc">$</span>Species)</span>
<span id="cb28-6"><a href="chapter6.html#cb28-6" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         13         2
##   virginica       0          2        13
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9111          
##                  95% CI : (0.7878, 0.9752)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 8.467e-16       
##                                           
##                   Kappa : 0.8667          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            0.8667           0.8667
## Specificity                 1.0000            0.9333           0.9333
## Pos Pred Value              1.0000            0.8667           0.8667
## Neg Pred Value              1.0000            0.9333           0.9333
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.2889           0.2889
## Detection Prevalence        0.3333            0.3333           0.3333
## Balanced Accuracy           1.0000            0.9000           0.9000</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="chapter6.html#cb30-1" tabindex="-1"></a><span class="co"># Visualizing the prediction results using ggplot2</span></span>
<span id="cb30-2"><a href="chapter6.html#cb30-2" tabindex="-1"></a>test_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(test_data, <span class="at">Predicted =</span> nb_predictions)</span>
<span id="cb30-3"><a href="chapter6.html#cb30-3" tabindex="-1"></a></span>
<span id="cb30-4"><a href="chapter6.html#cb30-4" tabindex="-1"></a><span class="fu">ggplot</span>(test_results, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb30-5"><a href="chapter6.html#cb30-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb30-6"><a href="chapter6.html#cb30-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Naive Bayes Classification on Iris Dataset&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-7"><a href="chapter6.html#cb30-7" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb30-8"><a href="chapter6.html#cb30-8" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/naive-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="neural-network" class="section level4 unnumbered hasAnchor">
<h4>Neural network<a href="chapter6.html#neural-network" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f7.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="chapter6.html#cb31-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb31-2"><a href="chapter6.html#cb31-2" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb31-3"><a href="chapter6.html#cb31-3" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb31-4"><a href="chapter6.html#cb31-4" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb31-5"><a href="chapter6.html#cb31-5" tabindex="-1"></a></span>
<span id="cb31-6"><a href="chapter6.html#cb31-6" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb31-7"><a href="chapter6.html#cb31-7" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb31-8"><a href="chapter6.html#cb31-8" tabindex="-1"></a></span>
<span id="cb31-9"><a href="chapter6.html#cb31-9" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb31-10"><a href="chapter6.html#cb31-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb31-11"><a href="chapter6.html#cb31-11" tabindex="-1"></a></span>
<span id="cb31-12"><a href="chapter6.html#cb31-12" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (70% train, 30% test)</span></span>
<span id="cb31-13"><a href="chapter6.html#cb31-13" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(iris<span class="sc">$</span>Species, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb31-14"><a href="chapter6.html#cb31-14" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> iris[train_index, ]</span>
<span id="cb31-15"><a href="chapter6.html#cb31-15" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> iris[<span class="sc">-</span>train_index, ]</span>
<span id="cb31-16"><a href="chapter6.html#cb31-16" tabindex="-1"></a></span>
<span id="cb31-17"><a href="chapter6.html#cb31-17" tabindex="-1"></a><span class="co"># Build a Neural Network model (1 hidden layer with 5 neurons)</span></span>
<span id="cb31-18"><a href="chapter6.html#cb31-18" tabindex="-1"></a>nn_model <span class="ot">&lt;-</span> <span class="fu">nnet</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, </span>
<span id="cb31-19"><a href="chapter6.html#cb31-19" tabindex="-1"></a>                 <span class="at">data =</span> train_data, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">linout =</span> <span class="cn">FALSE</span>, <span class="at">skip =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # weights:  55
## initial  value 182.177927 
## iter  10 value 5.275640
## iter  20 value 3.361243
## iter  30 value 1.318482
## iter  40 value 0.016181
## iter  50 value 0.000591
## final  value 0.000058 
## converged</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="chapter6.html#cb33-1" tabindex="-1"></a><span class="co"># Print the Neural Network model summary</span></span>
<span id="cb33-2"><a href="chapter6.html#cb33-2" tabindex="-1"></a><span class="fu">print</span>(nn_model)</span></code></pre></div>
<pre><code>## a 4-5-3 network with 55 weights
## inputs: Sepal.Length Sepal.Width Petal.Length Petal.Width 
## output(s): Species 
## options were - skip-layer connections  softmax modelling</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="chapter6.html#cb35-1" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb35-2"><a href="chapter6.html#cb35-2" tabindex="-1"></a>nn_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(nn_model, test_data, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb35-3"><a href="chapter6.html#cb35-3" tabindex="-1"></a></span>
<span id="cb35-4"><a href="chapter6.html#cb35-4" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb35-5"><a href="chapter6.html#cb35-5" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(nn_predictions), test_data<span class="sc">$</span>Species)</span>
<span id="cb35-6"><a href="chapter6.html#cb35-6" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         15         2
##   virginica       0          0        13
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9556          
##                  95% CI : (0.8485, 0.9946)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9333          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.8667
## Specificity                 1.0000            0.9333           1.0000
## Pos Pred Value              1.0000            0.8824           1.0000
## Neg Pred Value              1.0000            1.0000           0.9375
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2889
## Detection Prevalence        0.3333            0.3778           0.2889
## Balanced Accuracy           1.0000            0.9667           0.9333</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="chapter6.html#cb37-1" tabindex="-1"></a><span class="co"># Visualizing the prediction results using ggplot2</span></span>
<span id="cb37-2"><a href="chapter6.html#cb37-2" tabindex="-1"></a>test_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(test_data, <span class="at">Predicted =</span> nn_predictions)</span>
<span id="cb37-3"><a href="chapter6.html#cb37-3" tabindex="-1"></a></span>
<span id="cb37-4"><a href="chapter6.html#cb37-4" tabindex="-1"></a><span class="fu">ggplot</span>(test_results, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb37-5"><a href="chapter6.html#cb37-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb37-6"><a href="chapter6.html#cb37-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Neural Network Classification on Iris Dataset&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb37-7"><a href="chapter6.html#cb37-7" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb37-8"><a href="chapter6.html#cb37-8" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/neural-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="support-vector-machines" class="section level4 unnumbered hasAnchor">
<h4>Support vector machines<a href="chapter6.html#support-vector-machines" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f8.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="chapter6.html#cb38-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb38-2"><a href="chapter6.html#cb38-2" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb38-3"><a href="chapter6.html#cb38-3" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb38-4"><a href="chapter6.html#cb38-4" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb38-5"><a href="chapter6.html#cb38-5" tabindex="-1"></a></span>
<span id="cb38-6"><a href="chapter6.html#cb38-6" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb38-7"><a href="chapter6.html#cb38-7" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb38-8"><a href="chapter6.html#cb38-8" tabindex="-1"></a></span>
<span id="cb38-9"><a href="chapter6.html#cb38-9" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb38-10"><a href="chapter6.html#cb38-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb38-11"><a href="chapter6.html#cb38-11" tabindex="-1"></a></span>
<span id="cb38-12"><a href="chapter6.html#cb38-12" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (70% train, 30% test)</span></span>
<span id="cb38-13"><a href="chapter6.html#cb38-13" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(iris<span class="sc">$</span>Species, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb38-14"><a href="chapter6.html#cb38-14" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> iris[train_index, ]</span>
<span id="cb38-15"><a href="chapter6.html#cb38-15" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> iris[<span class="sc">-</span>train_index, ]</span>
<span id="cb38-16"><a href="chapter6.html#cb38-16" tabindex="-1"></a></span>
<span id="cb38-17"><a href="chapter6.html#cb38-17" tabindex="-1"></a><span class="co"># Build an SVM model</span></span>
<span id="cb38-18"><a href="chapter6.html#cb38-18" tabindex="-1"></a>svm_model <span class="ot">&lt;-</span> <span class="fu">svm</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, </span>
<span id="cb38-19"><a href="chapter6.html#cb38-19" tabindex="-1"></a>                 <span class="at">data =</span> train_data, <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb38-20"><a href="chapter6.html#cb38-20" tabindex="-1"></a></span>
<span id="cb38-21"><a href="chapter6.html#cb38-21" tabindex="-1"></a><span class="co"># Print the SVM model summary</span></span>
<span id="cb38-22"><a href="chapter6.html#cb38-22" tabindex="-1"></a><span class="fu">print</span>(svm_model)</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = Species ~ Sepal.Length + Sepal.Width + Petal.Length + 
##     Petal.Width, data = train_data, kernel = &quot;linear&quot;)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  1 
## 
## Number of Support Vectors:  22</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="chapter6.html#cb40-1" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb40-2"><a href="chapter6.html#cb40-2" tabindex="-1"></a>svm_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_model, test_data)</span>
<span id="cb40-3"><a href="chapter6.html#cb40-3" tabindex="-1"></a></span>
<span id="cb40-4"><a href="chapter6.html#cb40-4" tabindex="-1"></a><span class="co"># Confusion Matrix to evaluate the model&#39;s performance</span></span>
<span id="cb40-5"><a href="chapter6.html#cb40-5" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(svm_predictions, test_data<span class="sc">$</span>Species)</span>
<span id="cb40-6"><a href="chapter6.html#cb40-6" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         15         1
##   virginica       0          0        14
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9778          
##                  95% CI : (0.8823, 0.9994)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9667          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.9333
## Specificity                 1.0000            0.9667           1.0000
## Pos Pred Value              1.0000            0.9375           1.0000
## Neg Pred Value              1.0000            1.0000           0.9677
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.3111
## Detection Prevalence        0.3333            0.3556           0.3111
## Balanced Accuracy           1.0000            0.9833           0.9667</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="chapter6.html#cb42-1" tabindex="-1"></a><span class="co"># Visualizing the prediction results using ggplot2</span></span>
<span id="cb42-2"><a href="chapter6.html#cb42-2" tabindex="-1"></a>test_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(test_data, <span class="at">Predicted =</span> svm_predictions)</span>
<span id="cb42-3"><a href="chapter6.html#cb42-3" tabindex="-1"></a></span>
<span id="cb42-4"><a href="chapter6.html#cb42-4" tabindex="-1"></a><span class="fu">ggplot</span>(test_results, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb42-5"><a href="chapter6.html#cb42-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb42-6"><a href="chapter6.html#cb42-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;SVM Classification on Iris Dataset&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb42-7"><a href="chapter6.html#cb42-7" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb42-8"><a href="chapter6.html#cb42-8" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/svm-1.png" width="672" /></p>
<p><br></p>
</div>
</div>
<div id="예측분석" class="section level3 hasAnchor" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> 예측분석<a href="chapter6.html#예측분석" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>예측(prediction or forecasting)은 연속적 수치값의 정확한 예측을 목표로 함</p></li>
<li><p>예측분석 또한 지도학습으로 분류되며, 출력변수가 범주가 아니라 수치값이라는 점에서 분류분석과 차이가 있음</p>
<ul>
<li>예측분석은 입력변수와 출력변수 간의 관계의 모형을 통해 출력변수를 예측하는 회귀분석(regression analysis)과 시간을 두고 관측되는 출력변수를 과거 기록의 패턴에 근거하여 미래 시점의 출력변수를 예측하는 데 목적이 있는 시계열분석(time series analysis)으로 대별됨</li>
</ul></li>
</ul>
<div id="regression-analysis" class="section level4 unnumbered hasAnchor">
<h4>Regression analysis<a href="chapter6.html#regression-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f9.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="chapter6.html#cb43-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb43-2"><a href="chapter6.html#cb43-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb43-3"><a href="chapter6.html#cb43-3" tabindex="-1"></a></span>
<span id="cb43-4"><a href="chapter6.html#cb43-4" tabindex="-1"></a><span class="co"># Load the mtcars dataset</span></span>
<span id="cb43-5"><a href="chapter6.html#cb43-5" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb43-6"><a href="chapter6.html#cb43-6" tabindex="-1"></a></span>
<span id="cb43-7"><a href="chapter6.html#cb43-7" tabindex="-1"></a><span class="co"># Perform linear regression (mpg ~ wt)</span></span>
<span id="cb43-8"><a href="chapter6.html#cb43-8" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb43-9"><a href="chapter6.html#cb43-9" tabindex="-1"></a></span>
<span id="cb43-10"><a href="chapter6.html#cb43-10" tabindex="-1"></a><span class="co"># Print the summary of the model</span></span>
<span id="cb43-11"><a href="chapter6.html#cb43-11" tabindex="-1"></a><span class="fu">summary</span>(lm_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5432 -2.3647 -0.1252  1.4096  6.8727 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
## wt           -5.3445     0.5591  -9.559 1.29e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.046 on 30 degrees of freedom
## Multiple R-squared:  0.7528, Adjusted R-squared:  0.7446 
## F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="chapter6.html#cb45-1" tabindex="-1"></a><span class="co"># Make predictions using the model</span></span>
<span id="cb45-2"><a href="chapter6.html#cb45-2" tabindex="-1"></a>mtcars<span class="sc">$</span>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_model, mtcars)</span>
<span id="cb45-3"><a href="chapter6.html#cb45-3" tabindex="-1"></a></span>
<span id="cb45-4"><a href="chapter6.html#cb45-4" tabindex="-1"></a><span class="co"># Plot the data and the regression line using ggplot2</span></span>
<span id="cb45-5"><a href="chapter6.html#cb45-5" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb45-6"><a href="chapter6.html#cb45-6" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>  <span class="co"># Plot the actual data points</span></span>
<span id="cb45-7"><a href="chapter6.html#cb45-7" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span>  <span class="co"># Add the regression line</span></span>
<span id="cb45-8"><a href="chapter6.html#cb45-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Linear Regression: mpg vs. wt&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Weight (wt)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Miles per Gallon (mpg)&quot;</span>) <span class="sc">+</span></span>
<span id="cb45-9"><a href="chapter6.html#cb45-9" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/regression-1.png" width="672" /></p>
</div>
<div id="k-nearest-neighbor-1" class="section level4 unnumbered hasAnchor">
<h4>K-nearest neighbor<a href="chapter6.html#k-nearest-neighbor-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f10.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="chapter6.html#cb46-1" tabindex="-1"></a><span class="fu">library</span>(FNN)</span>
<span id="cb46-2"><a href="chapter6.html#cb46-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb46-3"><a href="chapter6.html#cb46-3" tabindex="-1"></a></span>
<span id="cb46-4"><a href="chapter6.html#cb46-4" tabindex="-1"></a><span class="co"># Load the mtcars dataset</span></span>
<span id="cb46-5"><a href="chapter6.html#cb46-5" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb46-6"><a href="chapter6.html#cb46-6" tabindex="-1"></a></span>
<span id="cb46-7"><a href="chapter6.html#cb46-7" tabindex="-1"></a><span class="co"># Set the number of neighbors (k)</span></span>
<span id="cb46-8"><a href="chapter6.html#cb46-8" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb46-9"><a href="chapter6.html#cb46-9" tabindex="-1"></a></span>
<span id="cb46-10"><a href="chapter6.html#cb46-10" tabindex="-1"></a><span class="co"># Perform KNN regression (predict mpg based on wt)</span></span>
<span id="cb46-11"><a href="chapter6.html#cb46-11" tabindex="-1"></a>knn_predictions <span class="ot">&lt;-</span> <span class="fu">knn.reg</span>(<span class="at">train =</span> mtcars[<span class="st">&quot;wt&quot;</span>], <span class="at">test =</span> mtcars[<span class="st">&quot;wt&quot;</span>], <span class="at">y =</span> mtcars[<span class="st">&quot;mpg&quot;</span>], <span class="at">k =</span> k)</span>
<span id="cb46-12"><a href="chapter6.html#cb46-12" tabindex="-1"></a></span>
<span id="cb46-13"><a href="chapter6.html#cb46-13" tabindex="-1"></a><span class="co"># Add the predictions to the dataset</span></span>
<span id="cb46-14"><a href="chapter6.html#cb46-14" tabindex="-1"></a>mtcars<span class="sc">$</span>knn_predictions <span class="ot">&lt;-</span> knn_predictions<span class="sc">$</span>pred</span>
<span id="cb46-15"><a href="chapter6.html#cb46-15" tabindex="-1"></a></span>
<span id="cb46-16"><a href="chapter6.html#cb46-16" tabindex="-1"></a><span class="co"># Plot the actual vs predicted values using ggplot2</span></span>
<span id="cb46-17"><a href="chapter6.html#cb46-17" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb46-18"><a href="chapter6.html#cb46-18" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span>  <span class="co"># Actual data points</span></span>
<span id="cb46-19"><a href="chapter6.html#cb46-19" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> knn_predictions), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span>  <span class="co"># KNN regression line</span></span>
<span id="cb46-20"><a href="chapter6.html#cb46-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;KNN Regression: mpg vs. wt&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Weight (wt)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Miles per Gallon (mpg)&quot;</span>) <span class="sc">+</span></span>
<span id="cb46-21"><a href="chapter6.html#cb46-21" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/knnr-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="neural-network-1" class="section level4 unnumbered hasAnchor">
<h4>Neural network<a href="chapter6.html#neural-network-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f11.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="chapter6.html#cb47-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb47-2"><a href="chapter6.html#cb47-2" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb47-3"><a href="chapter6.html#cb47-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb47-4"><a href="chapter6.html#cb47-4" tabindex="-1"></a></span>
<span id="cb47-5"><a href="chapter6.html#cb47-5" tabindex="-1"></a><span class="co"># Load the mtcars dataset</span></span>
<span id="cb47-6"><a href="chapter6.html#cb47-6" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb47-7"><a href="chapter6.html#cb47-7" tabindex="-1"></a></span>
<span id="cb47-8"><a href="chapter6.html#cb47-8" tabindex="-1"></a><span class="co"># Build a Neural Network model for regression (1 hidden layer with 5 neurons)</span></span>
<span id="cb47-9"><a href="chapter6.html#cb47-9" tabindex="-1"></a>nn_model <span class="ot">&lt;-</span> <span class="fu">nnet</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">linout =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # weights:  16
## initial  value 14156.667582 
## iter  10 value 408.371141
## iter  20 value 252.547442
## iter  30 value 200.201465
## iter  40 value 199.527292
## iter  50 value 198.171578
## iter  60 value 193.219528
## iter  70 value 179.086944
## iter  80 value 170.386327
## iter  90 value 170.283620
## iter 100 value 168.916921
## final  value 168.916921 
## stopped after 100 iterations</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="chapter6.html#cb49-1" tabindex="-1"></a><span class="co"># Print the model summary</span></span>
<span id="cb49-2"><a href="chapter6.html#cb49-2" tabindex="-1"></a><span class="fu">summary</span>(nn_model)</span></code></pre></div>
<pre><code>## a 1-5-1 network with 16 weights
## options were - linear output units 
##  b-&gt;h1 i1-&gt;h1 
##   3.27   5.39 
##  b-&gt;h2 i1-&gt;h2 
##   6.73  11.08 
##  b-&gt;h3 i1-&gt;h3 
## 167.02 -73.36 
##  b-&gt;h4 i1-&gt;h4 
##   1.99  -0.74 
##  b-&gt;h5 i1-&gt;h5 
##   5.19   8.77 
##   b-&gt;o  h1-&gt;o  h2-&gt;o  h3-&gt;o  h4-&gt;o  h5-&gt;o 
##   5.23   1.43  -0.03   5.22  24.98   2.10</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="chapter6.html#cb51-1" tabindex="-1"></a><span class="co"># Make predictions using the neural network</span></span>
<span id="cb51-2"><a href="chapter6.html#cb51-2" tabindex="-1"></a>mtcars<span class="sc">$</span>nn_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(nn_model, mtcars)</span>
<span id="cb51-3"><a href="chapter6.html#cb51-3" tabindex="-1"></a></span>
<span id="cb51-4"><a href="chapter6.html#cb51-4" tabindex="-1"></a><span class="co"># Plot the actual vs predicted values using ggplot2</span></span>
<span id="cb51-5"><a href="chapter6.html#cb51-5" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb51-6"><a href="chapter6.html#cb51-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span>  <span class="co"># Actual data points</span></span>
<span id="cb51-7"><a href="chapter6.html#cb51-7" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> nn_predictions), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span>  <span class="co"># Neural Network regression line</span></span>
<span id="cb51-8"><a href="chapter6.html#cb51-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Neural Network Regression: mpg vs. wt&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Weight (wt)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Miles per Gallon (mpg)&quot;</span>) <span class="sc">+</span></span>
<span id="cb51-9"><a href="chapter6.html#cb51-9" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/nnr-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="smoothing" class="section level4 unnumbered hasAnchor">
<h4>Smoothing<a href="chapter6.html#smoothing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f12.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="chapter6.html#cb52-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb52-2"><a href="chapter6.html#cb52-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb52-3"><a href="chapter6.html#cb52-3" tabindex="-1"></a></span>
<span id="cb52-4"><a href="chapter6.html#cb52-4" tabindex="-1"></a><span class="co"># Load the mtcars dataset</span></span>
<span id="cb52-5"><a href="chapter6.html#cb52-5" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb52-6"><a href="chapter6.html#cb52-6" tabindex="-1"></a></span>
<span id="cb52-7"><a href="chapter6.html#cb52-7" tabindex="-1"></a><span class="co"># Perform LOWESS smoothing</span></span>
<span id="cb52-8"><a href="chapter6.html#cb52-8" tabindex="-1"></a>lowess_fit <span class="ot">&lt;-</span> <span class="fu">loess</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb52-9"><a href="chapter6.html#cb52-9" tabindex="-1"></a></span>
<span id="cb52-10"><a href="chapter6.html#cb52-10" tabindex="-1"></a><span class="co"># Generate predictions from the LOWESS model</span></span>
<span id="cb52-11"><a href="chapter6.html#cb52-11" tabindex="-1"></a>mtcars<span class="sc">$</span>lowess_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(lowess_fit)</span>
<span id="cb52-12"><a href="chapter6.html#cb52-12" tabindex="-1"></a></span>
<span id="cb52-13"><a href="chapter6.html#cb52-13" tabindex="-1"></a><span class="co"># Plot the actual data and the smoothed line using ggplot2</span></span>
<span id="cb52-14"><a href="chapter6.html#cb52-14" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb52-15"><a href="chapter6.html#cb52-15" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span>  <span class="co"># Actual data points</span></span>
<span id="cb52-16"><a href="chapter6.html#cb52-16" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> lowess_predictions), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span>  <span class="co"># LOWESS smoothing line</span></span>
<span id="cb52-17"><a href="chapter6.html#cb52-17" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;LOWESS Smoothing: mpg vs. wt&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Weight (wt)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Miles per Gallon (mpg)&quot;</span>) <span class="sc">+</span></span>
<span id="cb52-18"><a href="chapter6.html#cb52-18" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/lowess-1.png" width="672" /></p>
<p><br></p>
</div>
</div>
<div id="군집분석" class="section level3 hasAnchor" number="6.4.4">
<h3><span class="header-section-number">6.4.4</span> 군집분석<a href="chapter6.html#군집분석" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>자료가 가진 특성에 따라 자료를 여러 개의 배타적인 집단으로 나누는 기법</p></li>
<li><p>자료 객체들은 ‘군집 내 유사성의 극대화, 군집 간 유사성의 최소화’ 원칙을 토대로 군집화됨</p></li>
<li><p>군집분석의 일차적인 목표는 적절한 군집으로 나누는 것이지만, 그 결과를 토대로 각 군집의 특성, 군집 간 차이 등에 관하여 분석함으로써 숨겨진 유용한 정보를 발견할 수 있음</p>
<ul>
<li>군집분석을 통해 얻은 군집을 결과변수로 활용하여 분류분석에 적용함으로써 유용한 규칙을 유도할 수 있음</li>
</ul></li>
<li><p>군집화는 분류법을 만드는 데에도 이용할 수 있으며, 유사한 사건들을 묶어서 관찰결과를 군집의 계층(hierarchy)으로 조직화하는데 유용함</p></li>
</ul>
<div id="k-means" class="section level4 unnumbered hasAnchor">
<h4>K-means<a href="chapter6.html#k-means" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f13.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="chapter6.html#cb53-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb53-2"><a href="chapter6.html#cb53-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb53-3"><a href="chapter6.html#cb53-3" tabindex="-1"></a></span>
<span id="cb53-4"><a href="chapter6.html#cb53-4" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb53-5"><a href="chapter6.html#cb53-5" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb53-6"><a href="chapter6.html#cb53-6" tabindex="-1"></a></span>
<span id="cb53-7"><a href="chapter6.html#cb53-7" tabindex="-1"></a><span class="co"># Perform k-means clustering with k = 3 (since there are 3 species in the iris dataset)</span></span>
<span id="cb53-8"><a href="chapter6.html#cb53-8" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># Set seed for reproducibility</span></span>
<span id="cb53-9"><a href="chapter6.html#cb53-9" tabindex="-1"></a>kmeans_model <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(iris[, <span class="sc">-</span><span class="dv">5</span>], <span class="at">centers =</span> <span class="dv">3</span>)  <span class="co"># Exclude the species column</span></span>
<span id="cb53-10"><a href="chapter6.html#cb53-10" tabindex="-1"></a></span>
<span id="cb53-11"><a href="chapter6.html#cb53-11" tabindex="-1"></a><span class="co"># Print the k-means clustering result</span></span>
<span id="cb53-12"><a href="chapter6.html#cb53-12" tabindex="-1"></a><span class="fu">print</span>(kmeans_model)</span></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 50, 62, 38
## 
## Cluster means:
##   Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1     5.006000    3.428000     1.462000    0.246000
## 2     5.901613    2.748387     4.393548    1.433871
## 3     6.850000    3.073684     5.742105    2.071053
## 
## Clustering vector:
##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
##  [75] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3
## [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3
## [149] 3 2
## 
## Within cluster sum of squares by cluster:
## [1] 15.15100 39.82097 23.87947
##  (between_SS / total_SS =  88.4 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot;
## [6] &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="chapter6.html#cb55-1" tabindex="-1"></a><span class="co"># Add the cluster assignments to the original dataset</span></span>
<span id="cb55-2"><a href="chapter6.html#cb55-2" tabindex="-1"></a>iris<span class="sc">$</span>Cluster <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(kmeans_model<span class="sc">$</span>cluster)</span>
<span id="cb55-3"><a href="chapter6.html#cb55-3" tabindex="-1"></a></span>
<span id="cb55-4"><a href="chapter6.html#cb55-4" tabindex="-1"></a><span class="co"># Plot the k-means clustering result using ggplot2</span></span>
<span id="cb55-5"><a href="chapter6.html#cb55-5" tabindex="-1"></a><span class="fu">ggplot</span>(iris, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Cluster)) <span class="sc">+</span></span>
<span id="cb55-6"><a href="chapter6.html#cb55-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb55-7"><a href="chapter6.html#cb55-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;K-Means Clustering: Iris Dataset&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb55-8"><a href="chapter6.html#cb55-8" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb55-9"><a href="chapter6.html#cb55-9" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>)) <span class="sc">+</span></span>
<span id="cb55-10"><a href="chapter6.html#cb55-10" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/kmeans-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="hierarchical-clustering" class="section level4 unnumbered hasAnchor">
<h4>Hierarchical clustering<a href="chapter6.html#hierarchical-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f14.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="chapter6.html#cb56-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb56-2"><a href="chapter6.html#cb56-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb56-3"><a href="chapter6.html#cb56-3" tabindex="-1"></a></span>
<span id="cb56-4"><a href="chapter6.html#cb56-4" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb56-5"><a href="chapter6.html#cb56-5" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb56-6"><a href="chapter6.html#cb56-6" tabindex="-1"></a></span>
<span id="cb56-7"><a href="chapter6.html#cb56-7" tabindex="-1"></a><span class="co"># Perform hierarchical clustering</span></span>
<span id="cb56-8"><a href="chapter6.html#cb56-8" tabindex="-1"></a><span class="co"># Step 1: Compute the distance matrix (Euclidean distance)</span></span>
<span id="cb56-9"><a href="chapter6.html#cb56-9" tabindex="-1"></a>dist_matrix <span class="ot">&lt;-</span> <span class="fu">dist</span>(iris[, <span class="sc">-</span><span class="dv">5</span>])  <span class="co"># Exclude the Species column</span></span>
<span id="cb56-10"><a href="chapter6.html#cb56-10" tabindex="-1"></a></span>
<span id="cb56-11"><a href="chapter6.html#cb56-11" tabindex="-1"></a><span class="co"># Step 2: Apply hierarchical clustering</span></span>
<span id="cb56-12"><a href="chapter6.html#cb56-12" tabindex="-1"></a>hclust_model <span class="ot">&lt;-</span> <span class="fu">hclust</span>(dist_matrix, <span class="at">method =</span> <span class="st">&quot;ward.D2&quot;</span>)  <span class="co"># &quot;ward.D2&quot; minimizes variance within clusters</span></span>
<span id="cb56-13"><a href="chapter6.html#cb56-13" tabindex="-1"></a></span>
<span id="cb56-14"><a href="chapter6.html#cb56-14" tabindex="-1"></a><span class="co"># Step 3: Plot the dendrogram</span></span>
<span id="cb56-15"><a href="chapter6.html#cb56-15" tabindex="-1"></a><span class="fu">plot</span>(hclust_model, <span class="at">main =</span> <span class="st">&quot;Hierarchical Clustering Dendrogram&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Height&quot;</span>, <span class="at">sub =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/hrc-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="finite-mixture-model" class="section level4 unnumbered hasAnchor">
<h4>Finite mixture model<a href="chapter6.html#finite-mixture-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f15.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="chapter6.html#cb57-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb57-2"><a href="chapter6.html#cb57-2" tabindex="-1"></a><span class="fu">library</span>(mixtools)</span>
<span id="cb57-3"><a href="chapter6.html#cb57-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb57-4"><a href="chapter6.html#cb57-4" tabindex="-1"></a></span>
<span id="cb57-5"><a href="chapter6.html#cb57-5" tabindex="-1"></a><span class="co"># Load the iris dataset</span></span>
<span id="cb57-6"><a href="chapter6.html#cb57-6" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb57-7"><a href="chapter6.html#cb57-7" tabindex="-1"></a></span>
<span id="cb57-8"><a href="chapter6.html#cb57-8" tabindex="-1"></a><span class="co"># Fit a finite mixture model (Gaussian Mixture Model)</span></span>
<span id="cb57-9"><a href="chapter6.html#cb57-9" tabindex="-1"></a><span class="co"># We will use only the numeric columns (exclude &#39;Species&#39;)</span></span>
<span id="cb57-10"><a href="chapter6.html#cb57-10" tabindex="-1"></a>gmm_model <span class="ot">&lt;-</span> <span class="fu">mvnormalmixEM</span>(<span class="fu">as.matrix</span>(iris[, <span class="sc">-</span><span class="dv">5</span>]), <span class="at">k =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## number of iterations= 57</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="chapter6.html#cb59-1" tabindex="-1"></a><span class="co"># Print the model results</span></span>
<span id="cb59-2"><a href="chapter6.html#cb59-2" tabindex="-1"></a><span class="fu">print</span>(gmm_model)</span></code></pre></div>
<pre><code>## $x
##        Sepal.Length Sepal.Width Petal.Length Petal.Width
##   [1,]          5.1         3.5          1.4         0.2
##   [2,]          4.9         3.0          1.4         0.2
##   [3,]          4.7         3.2          1.3         0.2
##   [4,]          4.6         3.1          1.5         0.2
##   [5,]          5.0         3.6          1.4         0.2
##   [6,]          5.4         3.9          1.7         0.4
##   [7,]          4.6         3.4          1.4         0.3
##   [8,]          5.0         3.4          1.5         0.2
##   [9,]          4.4         2.9          1.4         0.2
##  [10,]          4.9         3.1          1.5         0.1
##  [11,]          5.4         3.7          1.5         0.2
##  [12,]          4.8         3.4          1.6         0.2
##  [13,]          4.8         3.0          1.4         0.1
##  [14,]          4.3         3.0          1.1         0.1
##  [15,]          5.8         4.0          1.2         0.2
##  [16,]          5.7         4.4          1.5         0.4
##  [17,]          5.4         3.9          1.3         0.4
##  [18,]          5.1         3.5          1.4         0.3
##  [19,]          5.7         3.8          1.7         0.3
##  [20,]          5.1         3.8          1.5         0.3
##  [21,]          5.4         3.4          1.7         0.2
##  [22,]          5.1         3.7          1.5         0.4
##  [23,]          4.6         3.6          1.0         0.2
##  [24,]          5.1         3.3          1.7         0.5
##  [25,]          4.8         3.4          1.9         0.2
##  [26,]          5.0         3.0          1.6         0.2
##  [27,]          5.0         3.4          1.6         0.4
##  [28,]          5.2         3.5          1.5         0.2
##  [29,]          5.2         3.4          1.4         0.2
##  [30,]          4.7         3.2          1.6         0.2
##  [31,]          4.8         3.1          1.6         0.2
##  [32,]          5.4         3.4          1.5         0.4
##  [33,]          5.2         4.1          1.5         0.1
##  [34,]          5.5         4.2          1.4         0.2
##  [35,]          4.9         3.1          1.5         0.2
##  [36,]          5.0         3.2          1.2         0.2
##  [37,]          5.5         3.5          1.3         0.2
##  [38,]          4.9         3.6          1.4         0.1
##  [39,]          4.4         3.0          1.3         0.2
##  [40,]          5.1         3.4          1.5         0.2
##  [41,]          5.0         3.5          1.3         0.3
##  [42,]          4.5         2.3          1.3         0.3
##  [43,]          4.4         3.2          1.3         0.2
##  [44,]          5.0         3.5          1.6         0.6
##  [45,]          5.1         3.8          1.9         0.4
##  [46,]          4.8         3.0          1.4         0.3
##  [47,]          5.1         3.8          1.6         0.2
##  [48,]          4.6         3.2          1.4         0.2
##  [49,]          5.3         3.7          1.5         0.2
##  [50,]          5.0         3.3          1.4         0.2
##  [51,]          7.0         3.2          4.7         1.4
##  [52,]          6.4         3.2          4.5         1.5
##  [53,]          6.9         3.1          4.9         1.5
##  [54,]          5.5         2.3          4.0         1.3
##  [55,]          6.5         2.8          4.6         1.5
##  [56,]          5.7         2.8          4.5         1.3
##  [57,]          6.3         3.3          4.7         1.6
##  [58,]          4.9         2.4          3.3         1.0
##  [59,]          6.6         2.9          4.6         1.3
##  [60,]          5.2         2.7          3.9         1.4
##  [61,]          5.0         2.0          3.5         1.0
##  [62,]          5.9         3.0          4.2         1.5
##  [63,]          6.0         2.2          4.0         1.0
##  [64,]          6.1         2.9          4.7         1.4
##  [65,]          5.6         2.9          3.6         1.3
##  [66,]          6.7         3.1          4.4         1.4
##  [67,]          5.6         3.0          4.5         1.5
##  [68,]          5.8         2.7          4.1         1.0
##  [69,]          6.2         2.2          4.5         1.5
##  [70,]          5.6         2.5          3.9         1.1
##  [71,]          5.9         3.2          4.8         1.8
##  [72,]          6.1         2.8          4.0         1.3
##  [73,]          6.3         2.5          4.9         1.5
##  [74,]          6.1         2.8          4.7         1.2
##  [75,]          6.4         2.9          4.3         1.3
##  [76,]          6.6         3.0          4.4         1.4
##  [77,]          6.8         2.8          4.8         1.4
##  [78,]          6.7         3.0          5.0         1.7
##  [79,]          6.0         2.9          4.5         1.5
##  [80,]          5.7         2.6          3.5         1.0
##  [81,]          5.5         2.4          3.8         1.1
##  [82,]          5.5         2.4          3.7         1.0
##  [83,]          5.8         2.7          3.9         1.2
##  [84,]          6.0         2.7          5.1         1.6
##  [85,]          5.4         3.0          4.5         1.5
##  [86,]          6.0         3.4          4.5         1.6
##  [87,]          6.7         3.1          4.7         1.5
##  [88,]          6.3         2.3          4.4         1.3
##  [89,]          5.6         3.0          4.1         1.3
##  [90,]          5.5         2.5          4.0         1.3
##  [91,]          5.5         2.6          4.4         1.2
##  [92,]          6.1         3.0          4.6         1.4
##  [93,]          5.8         2.6          4.0         1.2
##  [94,]          5.0         2.3          3.3         1.0
##  [95,]          5.6         2.7          4.2         1.3
##  [96,]          5.7         3.0          4.2         1.2
##  [97,]          5.7         2.9          4.2         1.3
##  [98,]          6.2         2.9          4.3         1.3
##  [99,]          5.1         2.5          3.0         1.1
## [100,]          5.7         2.8          4.1         1.3
## [101,]          6.3         3.3          6.0         2.5
## [102,]          5.8         2.7          5.1         1.9
## [103,]          7.1         3.0          5.9         2.1
## [104,]          6.3         2.9          5.6         1.8
## [105,]          6.5         3.0          5.8         2.2
## [106,]          7.6         3.0          6.6         2.1
## [107,]          4.9         2.5          4.5         1.7
## [108,]          7.3         2.9          6.3         1.8
## [109,]          6.7         2.5          5.8         1.8
## [110,]          7.2         3.6          6.1         2.5
## [111,]          6.5         3.2          5.1         2.0
## [112,]          6.4         2.7          5.3         1.9
## [113,]          6.8         3.0          5.5         2.1
## [114,]          5.7         2.5          5.0         2.0
## [115,]          5.8         2.8          5.1         2.4
## [116,]          6.4         3.2          5.3         2.3
## [117,]          6.5         3.0          5.5         1.8
## [118,]          7.7         3.8          6.7         2.2
## [119,]          7.7         2.6          6.9         2.3
## [120,]          6.0         2.2          5.0         1.5
## [121,]          6.9         3.2          5.7         2.3
## [122,]          5.6         2.8          4.9         2.0
## [123,]          7.7         2.8          6.7         2.0
## [124,]          6.3         2.7          4.9         1.8
## [125,]          6.7         3.3          5.7         2.1
## [126,]          7.2         3.2          6.0         1.8
## [127,]          6.2         2.8          4.8         1.8
## [128,]          6.1         3.0          4.9         1.8
## [129,]          6.4         2.8          5.6         2.1
## [130,]          7.2         3.0          5.8         1.6
## [131,]          7.4         2.8          6.1         1.9
## [132,]          7.9         3.8          6.4         2.0
## [133,]          6.4         2.8          5.6         2.2
## [134,]          6.3         2.8          5.1         1.5
## [135,]          6.1         2.6          5.6         1.4
## [136,]          7.7         3.0          6.1         2.3
## [137,]          6.3         3.4          5.6         2.4
## [138,]          6.4         3.1          5.5         1.8
## [139,]          6.0         3.0          4.8         1.8
## [140,]          6.9         3.1          5.4         2.1
## [141,]          6.7         3.1          5.6         2.4
## [142,]          6.9         3.1          5.1         2.3
## [143,]          5.8         2.7          5.1         1.9
## [144,]          6.8         3.2          5.9         2.3
## [145,]          6.7         3.3          5.7         2.5
## [146,]          6.7         3.0          5.2         2.3
## [147,]          6.3         2.5          5.0         1.9
## [148,]          6.5         3.0          5.2         2.0
## [149,]          6.2         3.4          5.4         2.3
## [150,]          5.9         3.0          5.1         1.8
## 
## $lambda
## [1] 0.1309712 0.3333308 0.5356980
## 
## $mu
## $mu[[1]]
## [1] 7.015962 2.956150 5.438290 1.673793
## 
## $mu[[2]]
## [1] 5.0060034 3.4280079 1.4620010 0.2459995
## 
## $mu[[3]]
## [1] 6.077658 2.851424 4.775845 1.676533
## 
## 
## $sigma
## $sigma[[1]]
##           [,1]       [,2]      [,3]       [,4]
## [1,] 0.2812954 0.10903782 0.4663081 0.15206795
## [2,] 0.1090378 0.14559946 0.1118830 0.03981441
## [3,] 0.4663081 0.11188299 0.9020284 0.29391391
## [4,] 0.1520679 0.03981441 0.2939139 0.10454040
## 
## $sigma[[2]]
##            [,1]        [,2]       [,3]        [,4]
## [1,] 0.12176311 0.097228763 0.01602754 0.010124248
## [2,] 0.09722876 0.140808178 0.01146282 0.009112508
## [3,] 0.01602754 0.011462823 0.02955602 0.005948080
## [4,] 0.01012425 0.009112508 0.00594808 0.010884029
## 
## $sigma[[3]]
##           [,1]       [,2]      [,3]       [,4]
## [1,] 0.2995731 0.10454382 0.3224691 0.16928439
## [2,] 0.1045438 0.09866486 0.1349552 0.08892329
## [3,] 0.3224691 0.13495517 0.5330472 0.28424950
## [4,] 0.1692844 0.08892329 0.2842495 0.19674303
## 
## 
## $loglik
## [1] -193.1443
## 
## $posterior
##              comp.1        comp.2       comp.3
##   [1,] 7.547113e-09  1.000000e+00 3.170135e-14
##   [2,] 4.376408e-07  9.999996e-01 1.193992e-09
##   [3,] 1.524963e-09  1.000000e+00 2.231291e-11
##   [4,] 2.487476e-11  1.000000e+00 2.246393e-09
##   [5,] 3.769156e-10  1.000000e+00 6.155001e-15
##   [6,] 2.674971e-08  1.000000e+00 2.229776e-16
##   [7,] 7.905396e-12  1.000000e+00 5.582722e-12
##   [8,] 2.267486e-09  1.000000e+00 1.578702e-12
##   [9,] 1.351974e-11  1.000000e+00 3.283174e-08
##  [10,] 3.909248e-09  1.000000e+00 1.927633e-09
##  [11,] 8.797176e-09  1.000000e+00 4.633654e-16
##  [12,] 7.771535e-12  1.000000e+00 2.111203e-11
##  [13,] 8.733527e-09  1.000000e+00 3.437424e-09
##  [14,] 1.430445e-11  1.000000e+00 2.265127e-09
##  [15,] 1.670110e-09  1.000000e+00 1.351309e-21
##  [16,] 6.801326e-10  1.000000e+00 1.720684e-24
##  [17,] 4.773316e-08  1.000000e+00 6.054115e-19
##  [18,] 4.634356e-08  1.000000e+00 3.265413e-14
##  [19,] 1.200235e-07  9.999999e-01 5.851712e-16
##  [20,] 3.448002e-10  1.000000e+00 1.987326e-16
##  [21,] 3.470528e-07  9.999997e-01 2.941675e-11
##  [22,] 1.054662e-08  1.000000e+00 4.400191e-15
##  [23,] 3.594179e-10  1.000000e+00 9.865056e-15
##  [24,] 1.985476e-05  9.999801e-01 2.174018e-09
##  [25,] 3.192421e-13  1.000000e+00 1.490898e-08
##  [26,] 5.826044e-07  9.999994e-01 2.429079e-08
##  [27,] 9.098211e-08  9.999999e-01 1.720699e-11
##  [28,] 1.316255e-08  1.000000e+00 9.298723e-14
##  [29,] 9.811192e-08  9.999999e-01 2.039839e-13
##  [30,] 1.716283e-11  1.000000e+00 1.318267e-09
##  [31,] 1.474139e-09  1.000000e+00 5.273757e-09
##  [32,] 9.079813e-06  9.999909e-01 8.592846e-13
##  [33,] 4.248851e-13  1.000000e+00 1.397987e-19
##  [34,] 1.204716e-10  1.000000e+00 1.634449e-22
##  [35,] 3.566905e-08  1.000000e+00 7.655670e-10
##  [36,] 9.686300e-07  9.999990e-01 2.878175e-12
##  [37,] 2.550468e-07  9.999997e-01 3.743101e-15
##  [38,] 6.196358e-12  1.000000e+00 2.095800e-14
##  [39,] 1.677472e-11  1.000000e+00 2.851282e-09
##  [40,] 1.265029e-08  1.000000e+00 1.117437e-12
##  [41,] 3.057408e-08  1.000000e+00 1.881964e-14
##  [42,] 3.259385e-04  9.996508e-01 2.328956e-05
##  [43,] 4.929211e-13  1.000000e+00 1.592541e-10
##  [44,] 1.541709e-06  9.999985e-01 1.519895e-10
##  [45,] 5.176062e-10  1.000000e+00 1.395003e-12
##  [46,] 5.070131e-07  9.999995e-01 1.442384e-09
##  [47,] 1.405020e-11  1.000000e+00 9.265433e-16
##  [48,] 2.255390e-11  1.000000e+00 1.144131e-10
##  [49,] 3.187197e-09  1.000000e+00 6.460161e-16
##  [50,] 2.702809e-08  1.000000e+00 2.935776e-12
##  [51,] 9.479450e-01  4.420665e-92 5.205498e-02
##  [52,] 1.473071e-01  5.673701e-83 8.526929e-01
##  [53,] 9.209485e-01 1.577037e-104 7.905146e-02
##  [54,] 7.412563e-05  5.173616e-64 9.999259e-01
##  [55,] 4.951892e-01  2.827498e-92 5.048108e-01
##  [56,] 4.308736e-08  3.493828e-79 1.000000e+00
##  [57,] 1.315954e-03  2.453458e-93 9.986840e-01
##  [58,] 1.138131e-09  1.036641e-33 1.000000e+00
##  [59,] 7.784635e-01  2.509038e-86 2.215365e-01
##  [60,] 4.361087e-12  1.589091e-60 1.000000e+00
##  [61,] 7.549370e-07  1.033031e-41 9.999992e-01
##  [62,] 4.134695e-05  2.159654e-72 9.999587e-01
##  [63,] 2.222363e-01  1.034738e-60 7.777637e-01
##  [64,] 5.025003e-04  1.755823e-90 9.994975e-01
##  [65,] 1.385236e-04  1.320291e-46 9.998615e-01
##  [66,] 8.803552e-01  4.970794e-79 1.196448e-01
##  [67,] 3.086002e-11  1.434997e-83 1.000000e+00
##  [68,] 6.069196e-05  2.184518e-58 9.999393e-01
##  [69,] 6.074163e-01  5.861945e-93 3.925837e-01
##  [70,] 2.671798e-04  2.092860e-54 9.997328e-01
##  [71,] 2.421371e-11 2.286549e-106 1.000000e+00
##  [72,] 2.507820e-01  1.388470e-61 7.492180e-01
##  [73,] 1.822890e-01 2.130834e-107 8.177110e-01
##  [74,] 1.402593e-04  2.134562e-86 9.998597e-01
##  [75,] 7.012757e-01  4.506042e-73 2.987243e-01
##  [76,] 8.112488e-01  1.272137e-79 1.887512e-01
##  [77,] 8.700699e-01 2.981980e-100 1.299301e-01
##  [78,] 2.252856e-01 2.991656e-115 7.747144e-01
##  [79,] 1.404574e-04  4.776146e-85 9.998595e-01
##  [80,] 9.156944e-02  2.858111e-39 9.084306e-01
##  [81,] 2.324753e-04  1.319252e-51 9.997675e-01
##  [82,] 3.854967e-04  2.003347e-46 9.996145e-01
##  [83,] 9.653081e-03  1.660690e-55 9.903469e-01
##  [84,] 1.233467e-06 1.248933e-116 9.999988e-01
##  [85,] 2.105720e-15  1.514170e-83 1.000000e+00
##  [86,] 5.310228e-07  1.038679e-83 9.999995e-01
##  [87,] 7.939399e-01  3.025505e-94 2.060601e-01
##  [88,] 8.190342e-01  2.901123e-83 1.809658e-01
##  [89,] 1.072522e-07  4.648536e-62 9.999999e-01
##  [90,] 5.126725e-06  1.654887e-62 9.999949e-01
##  [91,] 7.084680e-10  7.245129e-74 1.000000e+00
##  [92,] 7.357572e-04  3.257646e-85 9.992642e-01
##  [93,] 7.005775e-03  7.516589e-60 9.929942e-01
##  [94,] 2.703526e-07  2.122161e-34 9.999997e-01
##  [95,] 6.647592e-07  3.061793e-68 9.999993e-01
##  [96,] 6.078360e-07  4.043233e-63 9.999994e-01
##  [97,] 2.166406e-06  1.096622e-66 9.999978e-01
##  [98,] 1.648843e-01  7.840601e-72 8.351157e-01
##  [99,] 4.093477e-05  4.121166e-28 9.999591e-01
## [100,] 2.389967e-05  6.031623e-64 9.999761e-01
## [101,] 3.683410e-21 1.082392e-203 1.000000e+00
## [102,] 2.662844e-12 1.620376e-128 1.000000e+00
## [103,] 4.550270e-02 1.135006e-180 9.544973e-01
## [104,] 2.291660e-06 2.480755e-148 9.999977e-01
## [105,] 4.040019e-09 8.445471e-178 1.000000e+00
## [106,] 9.977676e-01 3.801561e-229 2.232408e-03
## [107,] 1.217785e-24  6.880227e-95 1.000000e+00
## [108,] 9.950115e-01 1.679233e-196 4.988522e-03
## [109,] 7.339581e-01 3.997459e-166 2.660419e-01
## [110,] 4.985527e-10 2.856398e-207 1.000000e+00
## [111,] 5.254891e-07 6.155080e-130 9.999995e-01
## [112,] 2.171689e-04 9.386687e-140 9.997828e-01
## [113,] 4.643029e-05 1.069494e-157 9.999536e-01
## [114,] 8.504330e-14 3.458894e-130 1.000000e+00
## [115,] 7.613722e-25 7.820008e-156 1.000000e+00
## [116,] 1.036115e-14 1.048930e-155 1.000000e+00
## [117,] 7.074091e-04 9.375582e-143 9.992926e-01
## [118,] 9.940072e-01 2.076401e-228 5.992773e-03
## [119,] 9.989534e-01 7.664435e-266 1.046572e-03
## [120,] 6.398117e-03 3.458567e-113 9.936019e-01
## [121,] 2.404475e-08 4.995141e-177 1.000000e+00
## [122,] 5.991402e-18 1.421844e-123 1.000000e+00
## [123,] 9.997940e-01 2.759098e-236 2.060050e-04
## [124,] 3.150708e-04 2.805065e-116 9.996849e-01
## [125,] 2.765321e-06 2.411570e-164 9.999972e-01
## [126,] 9.711348e-01 9.332842e-173 2.886522e-02
## [127,] 1.565085e-05 1.386695e-110 9.999843e-01
## [128,] 1.353858e-07 8.347218e-113 9.999999e-01
## [129,] 1.183459e-07 1.467348e-163 9.999999e-01
## [130,] 9.741260e-01 2.694481e-157 2.587404e-02
## [131,] 9.928039e-01 3.157597e-190 7.196118e-03
## [132,] 9.998034e-01 2.540818e-202 1.966101e-04
## [133,] 1.598572e-09 7.032981e-169 1.000000e+00
## [134,] 3.411921e-03 1.948149e-113 9.965881e-01
## [135,] 5.201382e-09 5.037129e-137 1.000000e+00
## [136,] 1.711980e-04 2.771601e-206 9.998288e-01
## [137,] 2.735903e-19 8.263830e-175 1.000000e+00
## [138,] 1.422591e-05 2.673134e-141 9.999858e-01
## [139,] 8.975520e-09 2.793557e-108 1.000000e+00
## [140,] 3.605093e-05 7.742487e-152 9.999639e-01
## [141,] 7.956139e-13 2.498472e-178 1.000000e+00
## [142,] 1.756596e-12 2.213666e-148 1.000000e+00
## [143,] 2.662844e-12 1.620376e-128 1.000000e+00
## [144,] 2.264518e-08 1.359442e-187 1.000000e+00
## [145,] 4.839878e-16 8.890669e-188 1.000000e+00
## [146,] 3.852649e-12 1.421666e-153 1.000000e+00
## [147,] 1.053304e-04 4.253248e-127 9.998947e-01
## [148,] 2.915801e-06 8.285388e-137 9.999971e-01
## [149,] 2.146818e-18 1.474027e-158 1.000000e+00
## [150,] 1.926454e-11 1.374945e-121 1.000000e+00
## 
## $all.loglik
##  [1] -1575.2286  -369.3695  -353.2343  -330.6506  -316.2846  -303.8607
##  [7]  -290.6036  -280.7154  -273.9650  -268.5458  -263.3770  -256.9850
## [13]  -247.3915  -227.7143  -198.5502  -198.2189  -197.6006  -196.2844
## [19]  -194.8270  -193.8566  -193.3319  -193.2143  -193.1805  -193.1655
## [25]  -193.1573  -193.1525  -193.1495  -193.1477  -193.1465  -193.1458
## [31]  -193.1453  -193.1450  -193.1447  -193.1446  -193.1445  -193.1445
## [37]  -193.1444  -193.1444  -193.1444  -193.1444  -193.1444  -193.1444
## [43]  -193.1444  -193.1443  -193.1443  -193.1443  -193.1443  -193.1443
## [49]  -193.1443  -193.1443  -193.1443  -193.1443  -193.1443  -193.1443
## [55]  -193.1443  -193.1443  -193.1443  -193.1443
## 
## $restarts
## [1] 0
## 
## $ft
## [1] &quot;mvnormalmixEM&quot;
## 
## attr(,&quot;class&quot;)
## [1] &quot;mixEM&quot;</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="chapter6.html#cb61-1" tabindex="-1"></a><span class="co"># Add the predicted cluster assignments to the iris dataset</span></span>
<span id="cb61-2"><a href="chapter6.html#cb61-2" tabindex="-1"></a>iris<span class="sc">$</span>Cluster <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">apply</span>(gmm_model<span class="sc">$</span>posterior,<span class="dv">1</span>,which.max)</span>
<span id="cb61-3"><a href="chapter6.html#cb61-3" tabindex="-1"></a>)</span>
<span id="cb61-4"><a href="chapter6.html#cb61-4" tabindex="-1"></a></span>
<span id="cb61-5"><a href="chapter6.html#cb61-5" tabindex="-1"></a><span class="co"># Plot the clusters using ggplot2</span></span>
<span id="cb61-6"><a href="chapter6.html#cb61-6" tabindex="-1"></a><span class="fu">ggplot</span>(iris, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Length, <span class="at">y =</span> Sepal.Width, <span class="at">color =</span> Cluster)) <span class="sc">+</span></span>
<span id="cb61-7"><a href="chapter6.html#cb61-7" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb61-8"><a href="chapter6.html#cb61-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Finite Mixture Model (Gaussian Mixture Model) Clustering: Iris Dataset&quot;</span>, </span>
<span id="cb61-9"><a href="chapter6.html#cb61-9" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Sepal Length&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sepal Width&quot;</span>) <span class="sc">+</span></span>
<span id="cb61-10"><a href="chapter6.html#cb61-10" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb61-11"><a href="chapter6.html#cb61-11" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>)) <span class="sc">+</span></span>
<span id="cb61-12"><a href="chapter6.html#cb61-12" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/mixture-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="biclustering-analysis" class="section level4 unnumbered hasAnchor">
<h4>Biclustering analysis<a href="chapter6.html#biclustering-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f13.jpg" style="width:80.0%" />
</center>
<p><br></p>
</div>
</div>
<div id="연관성-분석" class="section level3 hasAnchor" number="6.4.5">
<h3><span class="header-section-number">6.4.5</span> 연관성 분석<a href="chapter6.html#연관성-분석" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>연관성 분석(association analysis)은 주어진 데이터의 집합에서 동시에 빈번하게 발생하는 속성에 대한 조건을 나타내는 연관규칙(association rule)을 발견하는 것에 목적을 두고 있음</li>
</ul>
<div id="market-basket-analysis" class="section level4 unnumbered hasAnchor">
<h4>Market basket analysis<a href="chapter6.html#market-basket-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f16.jpg" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="chapter6.html#cb62-1" tabindex="-1"></a><span class="fu">library</span>(arules)</span>
<span id="cb62-2"><a href="chapter6.html#cb62-2" tabindex="-1"></a><span class="fu">library</span>(arulesViz)</span>
<span id="cb62-3"><a href="chapter6.html#cb62-3" tabindex="-1"></a></span>
<span id="cb62-4"><a href="chapter6.html#cb62-4" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Groceries&quot;</span>)</span>
<span id="cb62-5"><a href="chapter6.html#cb62-5" tabindex="-1"></a></span>
<span id="cb62-6"><a href="chapter6.html#cb62-6" tabindex="-1"></a><span class="co"># 연관 규칙 생성</span></span>
<span id="cb62-7"><a href="chapter6.html#cb62-7" tabindex="-1"></a>rules <span class="ot">&lt;-</span> <span class="fu">apriori</span>(Groceries, <span class="at">parameter=</span><span class="fu">list</span>(<span class="at">support=</span><span class="fl">0.01</span>, <span class="at">confidence=</span><span class="fl">0.5</span>, <span class="at">minlen=</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## Apriori
## 
## Parameter specification:
##  confidence minval smax arem  aval originalSupport maxtime support minlen
##         0.5    0.1    1 none FALSE            TRUE       5    0.01      2
##  maxlen target  ext
##      10  rules TRUE
## 
## Algorithmic control:
##  filter tree heap memopt load sort verbose
##     0.1 TRUE TRUE  FALSE TRUE    2    TRUE
## 
## Absolute minimum support count: 98 
## 
## set item appearances ...[0 item(s)] done [0.00s].
## set transactions ...[169 item(s), 9835 transaction(s)] done [0.00s].
## sorting and recoding items ... [88 item(s)] done [0.00s].
## creating transaction tree ... done [0.00s].
## checking subsets of size 1 2 3 4 done [0.00s].
## writing ... [15 rule(s)] done [0.00s].
## creating S4 object  ... done [0.00s].</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="chapter6.html#cb64-1" tabindex="-1"></a><span class="co"># 생성된 규칙 확인</span></span>
<span id="cb64-2"><a href="chapter6.html#cb64-2" tabindex="-1"></a><span class="fu">inspect</span>(rules)</span></code></pre></div>
<pre><code>##      lhs                                       rhs                support   
## [1]  {curd, yogurt}                         =&gt; {whole milk}       0.01006609
## [2]  {other vegetables, butter}             =&gt; {whole milk}       0.01148958
## [3]  {other vegetables, domestic eggs}      =&gt; {whole milk}       0.01230300
## [4]  {yogurt, whipped/sour cream}           =&gt; {whole milk}       0.01087951
## [5]  {other vegetables, whipped/sour cream} =&gt; {whole milk}       0.01464159
## [6]  {pip fruit, other vegetables}          =&gt; {whole milk}       0.01352313
## [7]  {citrus fruit, root vegetables}        =&gt; {other vegetables} 0.01037112
## [8]  {tropical fruit, root vegetables}      =&gt; {other vegetables} 0.01230300
## [9]  {tropical fruit, root vegetables}      =&gt; {whole milk}       0.01199797
## [10] {tropical fruit, yogurt}               =&gt; {whole milk}       0.01514997
## [11] {root vegetables, yogurt}              =&gt; {other vegetables} 0.01291307
## [12] {root vegetables, yogurt}              =&gt; {whole milk}       0.01453991
## [13] {root vegetables, rolls/buns}          =&gt; {other vegetables} 0.01220132
## [14] {root vegetables, rolls/buns}          =&gt; {whole milk}       0.01270971
## [15] {other vegetables, yogurt}             =&gt; {whole milk}       0.02226741
##      confidence coverage   lift     count
## [1]  0.5823529  0.01728521 2.279125  99  
## [2]  0.5736041  0.02003050 2.244885 113  
## [3]  0.5525114  0.02226741 2.162336 121  
## [4]  0.5245098  0.02074225 2.052747 107  
## [5]  0.5070423  0.02887646 1.984385 144  
## [6]  0.5175097  0.02613116 2.025351 133  
## [7]  0.5862069  0.01769192 3.029608 102  
## [8]  0.5845411  0.02104728 3.020999 121  
## [9]  0.5700483  0.02104728 2.230969 118  
## [10] 0.5173611  0.02928317 2.024770 149  
## [11] 0.5000000  0.02582613 2.584078 127  
## [12] 0.5629921  0.02582613 2.203354 143  
## [13] 0.5020921  0.02430097 2.594890 120  
## [14] 0.5230126  0.02430097 2.046888 125  
## [15] 0.5128806  0.04341637 2.007235 219</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="chapter6.html#cb66-1" tabindex="-1"></a><span class="co"># 1. 기본적인 히트맵 형식의 시각화</span></span>
<span id="cb66-2"><a href="chapter6.html#cb66-2" tabindex="-1"></a><span class="fu">plot</span>(rules)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/asso-1.png" width="672" /></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="chapter6.html#cb67-1" tabindex="-1"></a><span class="co"># 2. 그래프 형식으로 연관 규칙 시각화(아이템 간 관계)</span></span>
<span id="cb67-2"><a href="chapter6.html#cb67-2" tabindex="-1"></a><span class="fu">plot</span>(rules, <span class="at">method=</span><span class="st">&quot;graph&quot;</span>, <span class="at">control=</span><span class="fu">list</span>(<span class="at">type=</span><span class="st">&quot;items&quot;</span>))</span></code></pre></div>
<pre><code>## Available control parameters (with default values):
## layout    =  stress
## circular  =  FALSE
## ggraphdots    =  NULL
## edges     =  &lt;environment&gt;
## nodes     =  &lt;environment&gt;
## nodetext  =  &lt;environment&gt;
## colors    =  c(&quot;#EE0000FF&quot;, &quot;#EEEEEEFF&quot;)
## engine    =  ggplot2
## max   =  100
## verbose   =  FALSE</code></pre>
<p><img src="Introduction-to-Data-Science_files/figure-html/asso-2.png" width="672" /></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="chapter6.html#cb69-1" tabindex="-1"></a><span class="co"># 3. 품목별 연관 규칙 그룹 시각화</span></span>
<span id="cb69-2"><a href="chapter6.html#cb69-2" tabindex="-1"></a><span class="fu">plot</span>(rules, <span class="at">method=</span><span class="st">&quot;grouped&quot;</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/asso-3.png" width="672" /></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="chapter6.html#cb70-1" tabindex="-1"></a><span class="co"># 4. 산점도 형식의 시각화(규칙의 신뢰도와 지원도를 기반으로)</span></span>
<span id="cb70-2"><a href="chapter6.html#cb70-2" tabindex="-1"></a><span class="fu">plot</span>(rules, <span class="at">method=</span><span class="st">&quot;scatter&quot;</span>, <span class="at">measure=</span><span class="st">&quot;support&quot;</span>, <span class="at">shading=</span><span class="st">&quot;lift&quot;</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/asso-4.png" width="672" /></p>
<p><br></p>
</div>
<div id="sequence-analysis" class="section level4 unnumbered hasAnchor">
<h4>Sequence analysis<a href="chapter6.html#sequence-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<center>
<img src="fig6/f17.jpg" style="width:80.0%" />
</center>
<p><br></p>
</div>
</div>
<div id="텍스트마이닝" class="section level3 hasAnchor" number="6.4.6">
<h3><span class="header-section-number">6.4.6</span> 텍스트마이닝<a href="chapter6.html#텍스트마이닝" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>텍스트마이닝(text mining)은 다양한 포맷의 문서로부터 데이터를 획득하여 이를 문서별 단어의 매트릭스로 만들어 추가 분석이나 데이터마이닝 기법을 적용해 통찰(insight)을 얻거나 의사결정을 지원하는 방법임</p></li>
<li><p>웹콘텐츠나 PDF, 마이크로소프트 오피스 파일, 오라클 오픈오피스 파일, XML, 텍스트 파일 등 다양한 포맷의 문서로부터 텍스트를 추출함</p>
<ul>
<li>추출한 텍스트들 간의 관계를 이용해 감성분석(sentiment analysis)이나 워드 클라우드(word cloud)를 수행하고, 이 정보를 군집분석이나 분류분석, 사회연결망분석에 활용함</li>
<li>텍스트마이닝은 사회연결망분석과 함께 비정형 데이터마이닝에 속함</li>
</ul></li>
</ul>
<center>
<img src="fig6/f16.png" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="chapter6.html#cb71-1" tabindex="-1"></a><span class="co"># 패키지 로드</span></span>
<span id="cb71-2"><a href="chapter6.html#cb71-2" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb71-3"><a href="chapter6.html#cb71-3" tabindex="-1"></a><span class="fu">library</span>(wordcloud2)</span>
<span id="cb71-4"><a href="chapter6.html#cb71-4" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb71-5"><a href="chapter6.html#cb71-5" tabindex="-1"></a></span>
<span id="cb71-6"><a href="chapter6.html#cb71-6" tabindex="-1"></a><span class="co"># 데이터 사이언스 관련 텍스트 예시</span></span>
<span id="cb71-7"><a href="chapter6.html#cb71-7" tabindex="-1"></a>text_data <span class="ot">&lt;-</span> <span class="st">&quot;Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Data science is related to data mining, machine learning, big data, and statistics. Data scientists use data science techniques to analyze complex data sets, make predictions, and solve problems. The data science process includes data collection, data cleaning, data visualization, and statistical analysis. Data science is applied in various fields including finance, healthcare, marketing, and e-commerce.&quot;</span></span>
<span id="cb71-8"><a href="chapter6.html#cb71-8" tabindex="-1"></a></span>
<span id="cb71-9"><a href="chapter6.html#cb71-9" tabindex="-1"></a><span class="co"># 텍스트 데이터 프레임으로 변환</span></span>
<span id="cb71-10"><a href="chapter6.html#cb71-10" tabindex="-1"></a>text_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">text =</span> text_data, <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb71-11"><a href="chapter6.html#cb71-11" tabindex="-1"></a></span>
<span id="cb71-12"><a href="chapter6.html#cb71-12" tabindex="-1"></a><span class="co"># 텍스트를 tidy 형식으로 변환</span></span>
<span id="cb71-13"><a href="chapter6.html#cb71-13" tabindex="-1"></a>text_tidy <span class="ot">&lt;-</span> text_df <span class="sc">%&gt;%</span></span>
<span id="cb71-14"><a href="chapter6.html#cb71-14" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(word, text) <span class="sc">%&gt;%</span>   <span class="co"># 단어 단위로 토큰화</span></span>
<span id="cb71-15"><a href="chapter6.html#cb71-15" tabindex="-1"></a>  <span class="fu">anti_join</span>(stop_words)           <span class="co"># 불용어 제거</span></span>
<span id="cb71-16"><a href="chapter6.html#cb71-16" tabindex="-1"></a></span>
<span id="cb71-17"><a href="chapter6.html#cb71-17" tabindex="-1"></a><span class="co"># 단어 빈도 계산</span></span>
<span id="cb71-18"><a href="chapter6.html#cb71-18" tabindex="-1"></a>word_freq <span class="ot">&lt;-</span> text_tidy <span class="sc">%&gt;%</span></span>
<span id="cb71-19"><a href="chapter6.html#cb71-19" tabindex="-1"></a>  <span class="fu">count</span>(word, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span>
<span id="cb71-20"><a href="chapter6.html#cb71-20" tabindex="-1"></a></span>
<span id="cb71-21"><a href="chapter6.html#cb71-21" tabindex="-1"></a><span class="co"># 워드 클라우드 생성</span></span>
<span id="cb71-22"><a href="chapter6.html#cb71-22" tabindex="-1"></a><span class="fu">wordcloud2</span>(word_freq)</span></code></pre></div>
<div class="wordcloud2 html-widget html-fill-item" id="htmlwidget-44474b3e8cd160f85a98" style="width:672px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-44474b3e8cd160f85a98">{"x":{"word":["data","science","algorithms","analysis","analyze","applied","cleaning","collection","commerce","complex","extract","field","fields","finance","healthcare","includes","including","insights","interdisciplinary","knowledge","learning","machine","marketing","methods","mining","predictions","process","processes","related","scientific","scientists","sets","solve","statistical","statistics","structured","systems","techniques","unstructured","visualization"],"freq":[13,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"fontFamily":"Segoe UI","fontWeight":"bold","color":"random-dark","minSize":0,"weightFactor":13.84615384615385,"backgroundColor":"white","gridSize":0,"minRotation":-0.7853981633974483,"maxRotation":0.7853981633974483,"shuffle":true,"rotateRatio":0.4,"shape":"circle","ellipticity":0.65,"figBase64":null,"hover":null},"evals":[],"jsHooks":{"render":[{"code":"function(el,x){\n                        console.log(123);\n                        if(!iii){\n                          window.location.reload();\n                          iii = False;\n\n                        }\n  }","data":null}]}}</script>
<p><br></p>
</div>
<div id="사회연결망분석" class="section level3 hasAnchor" number="6.4.7">
<h3><span class="header-section-number">6.4.7</span> 사회연결망분석<a href="chapter6.html#사회연결망분석" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>사회연결망분석(social network analysis)은 개인과 집단들 간의 관계를 모델링하여 그것의 위상구조와 확산 진화과정을 계량적으로 분석하는 데이터마이닝 방법론</p></li>
<li><p>개인의 인간관계가 인터넷으로 확대된 사람 사이의 네트워크로, 사회과학뿐 아니라 경영학, 응용과학 등 다양한 분야에서 응용되고 있음</p></li>
<li><p>사회연결망분석 방법에는 집합론적인 방법, 그래프 이론에 의한 방법, 행렬을 이용한 방법 등</p></li>
</ul>
<center>
<img src="fig6/f18.jpg" style="width:80.0%" />
</center>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="chapter6.html#cb72-1" tabindex="-1"></a><span class="co"># 패키지 로드</span></span>
<span id="cb72-2"><a href="chapter6.html#cb72-2" tabindex="-1"></a><span class="fu">library</span>(igraph)</span>
<span id="cb72-3"><a href="chapter6.html#cb72-3" tabindex="-1"></a></span>
<span id="cb72-4"><a href="chapter6.html#cb72-4" tabindex="-1"></a><span class="co"># 네트워크 데이터 정의</span></span>
<span id="cb72-5"><a href="chapter6.html#cb72-5" tabindex="-1"></a>nodes <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">name =</span> <span class="fu">c</span>(<span class="st">&quot;Alice&quot;</span>, <span class="st">&quot;Bob&quot;</span>, <span class="st">&quot;Charlie&quot;</span>, <span class="st">&quot;David&quot;</span>, <span class="st">&quot;Eve&quot;</span>))</span>
<span id="cb72-6"><a href="chapter6.html#cb72-6" tabindex="-1"></a></span>
<span id="cb72-7"><a href="chapter6.html#cb72-7" tabindex="-1"></a><span class="co"># 엣지 데이터 정의 (친구 관계)</span></span>
<span id="cb72-8"><a href="chapter6.html#cb72-8" tabindex="-1"></a>edges <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">from =</span> <span class="fu">c</span>(<span class="st">&quot;Alice&quot;</span>, <span class="st">&quot;Alice&quot;</span>, <span class="st">&quot;Bob&quot;</span>, <span class="st">&quot;Charlie&quot;</span>, <span class="st">&quot;David&quot;</span>),</span>
<span id="cb72-9"><a href="chapter6.html#cb72-9" tabindex="-1"></a>                    <span class="at">to =</span> <span class="fu">c</span>(<span class="st">&quot;Bob&quot;</span>, <span class="st">&quot;Charlie&quot;</span>, <span class="st">&quot;David&quot;</span>, <span class="st">&quot;David&quot;</span>, <span class="st">&quot;Eve&quot;</span>))</span>
<span id="cb72-10"><a href="chapter6.html#cb72-10" tabindex="-1"></a></span>
<span id="cb72-11"><a href="chapter6.html#cb72-11" tabindex="-1"></a><span class="co"># 그래프 객체 생성</span></span>
<span id="cb72-12"><a href="chapter6.html#cb72-12" tabindex="-1"></a>g <span class="ot">&lt;-</span> <span class="fu">graph_from_data_frame</span>(edges, <span class="at">vertices =</span> nodes, <span class="at">directed =</span> <span class="cn">FALSE</span>)</span>
<span id="cb72-13"><a href="chapter6.html#cb72-13" tabindex="-1"></a></span>
<span id="cb72-14"><a href="chapter6.html#cb72-14" tabindex="-1"></a><span class="co"># 그래프 시각화</span></span>
<span id="cb72-15"><a href="chapter6.html#cb72-15" tabindex="-1"></a><span class="fu">plot</span>(g, <span class="at">vertex.size =</span> <span class="dv">30</span>, <span class="at">vertex.color =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">vertex.label.color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">edge.color =</span> <span class="st">&quot;gray&quot;</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/network-1.png" width="672" /></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="chapter6.html#cb73-1" tabindex="-1"></a><span class="co"># 각 노드의 연결 중심성 계산</span></span>
<span id="cb73-2"><a href="chapter6.html#cb73-2" tabindex="-1"></a>degree_cent <span class="ot">&lt;-</span> <span class="fu">degree</span>(g)</span>
<span id="cb73-3"><a href="chapter6.html#cb73-3" tabindex="-1"></a><span class="fu">print</span>(degree_cent)</span></code></pre></div>
<pre><code>##   Alice     Bob Charlie   David     Eve 
##       2       2       2       3       1</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="chapter6.html#cb75-1" tabindex="-1"></a><span class="co"># 네트워크 밀도 계산</span></span>
<span id="cb75-2"><a href="chapter6.html#cb75-2" tabindex="-1"></a>density <span class="ot">&lt;-</span> <span class="fu">edge_density</span>(g)</span>
<span id="cb75-3"><a href="chapter6.html#cb75-3" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Network Density: &quot;</span>, density))</span></code></pre></div>
<pre><code>## [1] &quot;Network Density:  0.5&quot;</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="chapter6.html#cb77-1" tabindex="-1"></a><span class="co"># 클러스터링 (모듈성 기반의 클러스터링)</span></span>
<span id="cb77-2"><a href="chapter6.html#cb77-2" tabindex="-1"></a>clusters <span class="ot">&lt;-</span> <span class="fu">cluster_fast_greedy</span>(g)</span>
<span id="cb77-3"><a href="chapter6.html#cb77-3" tabindex="-1"></a><span class="fu">print</span>(clusters)</span></code></pre></div>
<pre><code>## IGRAPH clustering fast greedy, groups: 2, mod: 0.08
## + groups:
##   $`1`
##   [1] &quot;Charlie&quot; &quot;David&quot;   &quot;Eve&quot;    
##   
##   $`2`
##   [1] &quot;Alice&quot; &quot;Bob&quot;  
## </code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="chapter6.html#cb79-1" tabindex="-1"></a><span class="co"># 클러스터 시각화</span></span>
<span id="cb79-2"><a href="chapter6.html#cb79-2" tabindex="-1"></a><span class="fu">plot</span>(clusters, g, <span class="at">vertex.size =</span> <span class="dv">30</span>, <span class="at">vertex.color =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">vertex.label.color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">edge.color =</span> <span class="st">&quot;gray&quot;</span>)</span></code></pre></div>
<p><img src="Introduction-to-Data-Science_files/figure-html/network-2.png" width="672" /></p>
<p><br></p>
</div>
<div id="데이터마이닝-분석도구" class="section level3 hasAnchor" number="6.4.8">
<h3><span class="header-section-number">6.4.8</span> 데이터마이닝 분석도구<a href="chapter6.html#데이터마이닝-분석도구" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>데이터마이닝 소프트웨어는 모든 데이터를 효과적으로 결합할 수 있어야 하며, 다양한 형태의 데이터베이스로부터 데이터를 통합할 수 있어야 함</p></li>
<li><p>주요 데이터베이스 관리 시스템 업체에서는 자사 소프트웨어에 데이터마이닝 기능을 포함시키는 경우가 많음</p>
<ul>
<li>IBM DB2 Intelligent Miner, Microsoft SQL Server 2005, Oracle Data Mining, Teradata Warehouse Miner 등</li>
</ul></li>
<li><p>데이터마이닝 주요 소프트웨어로는 SAS Enterprise Miner, IBM Modeler(이전의 SPSS Clementine), Spotfire Miner(이전의 Insightful Miner) 등이 있음</p></li>
<li><p>오픈소스인 R과 Python은 최근 알고리즘 및 기술반영이 상용 소프트웨어에 비할 수 있을만큼 빠른 장점이 있음</p></li>
</ul>
<p><br></p>
</div>
</div>
<div id="데이터마이닝-적용-사례" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> 데이터마이닝 적용 사례<a href="chapter6.html#데이터마이닝-적용-사례" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="신용카드사의-부정사용자-적발을-위한-데이터마이닝" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> 신용카드사의 부정사용자 적발을 위한 데이터마이닝<a href="chapter6.html#신용카드사의-부정사용자-적발을-위한-데이터마이닝" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>신용카드 부정사용의 종류를 간단히 살펴보면 다음과 같음
<ol style="list-style-type: decimal">
<li>분실 혹은 도난: 분실이나 도난에 의해 타인이 카드를 도용하는 경우</li>
<li>배달사고: 배달과정에서 타인이 카드를 받아 사용하는 경우</li>
<li>허위신청: 카드신청 단계부터 서류 등을 허위로 작성하여 카드를 발급받는 행위</li>
<li>카드위조: 신용카드 뒷면의 마그네틱 부분에 정상적으로 발급된 신용카드의 정보를 입력하는 경우</li>
<li>주변인의 사기: 본인의 인지 없이 주변인의 카드를 사용하거나 주변인의 카드를 발급 신청하는 등의 행위</li>
<li>불법현금융통: 현금 확보를 위해 실제 구입하지 않은 물건을 구매한 것으로 위장하는 행위</li>
</ol></li>
</ul>
<div id="사기적발의-원리-및-모델링" class="section level4 hasAnchor" number="6.5.1.1">
<h4><span class="header-section-number">6.5.1.1</span> 사기적발의 원리 및 모델링<a href="chapter6.html#사기적발의-원리-및-모델링" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>신용카드 거래자료로부터 불법으로 사용되는 거래를 검출하는 모형을 도출하여 시스템으로 구성하기까지는 여러 단계를 거쳐야 함
<ol style="list-style-type: decimal">
<li>단계 1: 문제의 정의 및 비즈니스의 이해</li>
<li>단계 2: 파생변수 생성 및 자료탐색</li>
<li>단계 3: 모형 적합 및 평가</li>
</ol></li>
<li>사기거래를 검출하는 것은 정상거래와 비정상거래의 분류문제로 귀결됨
<ul>
<li>신경망이나 기타 분류모형에서 계산되는 스코어(score)를 이용하여 사기거래 여부에 대해 의사결정을 내리는 것</li>
</ul></li>
</ul>
</div>
<div id="사기적발-시스템" class="section level4 hasAnchor" number="6.5.1.2">
<h4><span class="header-section-number">6.5.1.2</span> 사기적발 시스템<a href="chapter6.html#사기적발-시스템" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>데이터마이닝 분석과정을 통해 도출한 최종 모형은 실시간 거래자료를 대상으로 적용되어 스코어를 산출하며 사기거래 검출을 위해 사용되어야 함</li>
<li>자료를 모아 모형에 적용할 수 있는 형태로 가공하고 산출된 스코어로부터 의사결정을 내리며 사기거래로 의심되는 경우 내부적으로 감시함</li>
</ul>
<p><br></p>
</div>
</div>
<div id="이동통신사-고객이탈방지를-위한-데이터마이닝" class="section level3 hasAnchor" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> 이동통신사 고객이탈방지를 위한 데이터마이닝<a href="chapter6.html#이동통신사-고객이탈방지를-위한-데이터마이닝" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="고객관계관리-1" class="section level4 hasAnchor" number="6.5.2.1">
<h4><span class="header-section-number">6.5.2.1</span> 고객관계관리<a href="chapter6.html#고객관계관리-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>기업의 고객 개개인이 원하는 서비스를 제공하는 일대일 마케팅(one-to-one marketing)에 주력함
<ul>
<li>기업 마케팅 패러다임의 변화는 고객과의 관계, 즉 고객관계관리라는 단어를 탄생시킴</li>
</ul></li>
<li>효율적인 CRM (customer-driven market) 운영을 위한 닫힌 순환구조를 실현하기 위한 노력이 필요함
<ul>
<li>CRM에서 분석을 통해 수행활 수 있는 마케팅 전략으로는 다음과 같은 것들이 있음</li>
<li>고객확보 전략(acquisition): 신규고객 가능 대상을 파악하여 고객을 확보하거나 타사의 고객을 흡수하는 전략</li>
<li>이탈방지 전략(churn management): 기존 고객의 이탈을 방지하는 전략</li>
<li>되찾기 전략(win-back): 자사의 고객이었으나 타사의 고객으로 이동한 고객을 대상으로 다시 자사 고객이 되도록 유도하는 전략</li>
<li>교차판매 전략(cross-selling): 자사 고객에 대하여 새로운 자사의 서비스나 물건을 구입하게 하는 전략</li>
</ul></li>
</ul>
</div>
<div id="고객이탈방지" class="section level4 hasAnchor" number="6.5.2.2">
<h4><span class="header-section-number">6.5.2.2</span> 고객이탈방지<a href="chapter6.html#고객이탈방지" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>단계 1: 분석주제 정의 및 방향 설정</li>
</ol>
<ul>
<li><p>이동통신 해지 가능성을 나타내는 스코어는 0과 1 사이의 숫자로 표현되는데, 1에 가까울수록 해지 가능성이 높음</p></li>
<li><p>스코어를 중심으로 해지예방 캠페인의 대상을 어느 수준, 즉 스코어 상위 몇퍼센트까지의 고객을 대상으로 전개할 것인가에 대한 것은 다음과 같은 두 가지 기준에 의하여 결정할 수 있음</p>
<ul>
<li>일정 캠페인 기간 내에 관리 가능한 최대 고객 수를 결정한 후 해지 예상 스코어를 기준으로 관리 대상을 선정</li>
<li>스코어가 확률의 추정값이 경우, 정해진 ROI(return on investment)를 달성할 수 있는 고객의 수를 계산하여 관리</li>
</ul></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>단계 2: 파일럿 분석의 점검</p></li>
<li><p>단계 3: 변수생성 및 자료탐색</p></li>
<li><p>단계 4: 분류예측 모형 도출</p></li>
</ol>
<ul>
<li>단계별 고객이탈 과정과 그에 상응한 이탈방지 성공 여부</li>
</ul>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>고객의 종류</th>
<th>상대적 이탈방지 비용</th>
<th>상대적 이탈방지 성공률</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>기존 고객</td>
<td>대상고객의 수가 너무 많고 특성 또한 광범위하므로 상당히 많은 비용이 발생한다.</td>
<td>불특정 다수를 대상으로 불특정 방지수단을 사용하게 되므로 성공률이 낮다.</td>
</tr>
<tr class="even">
<td>이탈을 고려중인 고객</td>
<td>대상고객의 수가 복수의 고객군으로 한정되고, 고객군 간의 우선순위를 통하여 비용을 신축적으로 관리할 수 있다.</td>
<td>이탈을 고려 중인 고객을 대상으로 개별 고객에 가장 적절한 대응책을 취하면 성공률이 매우 높다.</td>
</tr>
<tr class="odd">
<td>이탈하고 있는 고객</td>
<td>대상고객이 실제 이탈고객으로 한정되어 대상고객 수가 줄어 1인당 비용이 변하지 않는 한 총비용은 일정하다.</td>
<td>이탈을 결정하고 이를 행동에 옮기고 있는 고객을 대상으로 한 대응조치는 성공활 가능성이 매우 낮다.</td>
</tr>
<tr class="even">
<td>이탈한 고객</td>
<td>이미 이탈한 고객을 대상으로 재가입을 권유하는 것은 상당한 인센티브 제공이 필요하다.</td>
<td>제공된 인센티브가 재가입을 촉진할지 여부는 불투명하다.</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
</div>
<div id="dna-칩-자료분석에서의-데이터마이닝" class="section level3 hasAnchor" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> DNA 칩 자료분석에서의 데이터마이닝<a href="chapter6.html#dna-칩-자료분석에서의-데이터마이닝" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="칩의-원리와-활용" class="section level4 hasAnchor" number="6.5.3.1">
<h4><span class="header-section-number">6.5.3.1</span> 칩의 원리와 활용<a href="chapter6.html#칩의-원리와-활용" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>수천 개의 유전자 혹은 유전자 조각의 발현 양상을 수량화한 자료를 얻을 수 있으며, 발현의 의미 있는 패턴을 찾기 위해 데이터마이닝 기법이 사용됨</li>
</ul>
</div>
<div id="데이터마이닝-분석-적용" class="section level4 hasAnchor" number="6.5.3.2">
<h4><span class="header-section-number">6.5.3.2</span> 데이터마이닝 분석 적용<a href="chapter6.html#데이터마이닝-분석-적용" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>유전자들의 기능을 밝히기 위해 마이크로어레이 자료에 군집분석이 사용됨</p></li>
<li><p>대표적으로 k-평균과 같은 분할적 방법(partitioning method)보다는 계층적 군집분석(hierarchical cluster analysis) 방법이 사용됨</p></li>
<li><p>히트맵의 상단과 좌측에 보이는 나뭇가지 모양의 그림을 수형도(dendrogram)라고 하는데 수형도의 끝은 하나의 유전자 또는 개체와 연결됨. 그림의 경우, 끝부분 간의 거리가 가까울수록 개체간의 유사성이 높음을 의미함</p>
<ul>
<li>계층적 군집화(hierarchical clustering)를 통하여 얻을 수 있음</li>
</ul></li>
<li><p>최근 마이크로어레이 자료를 이용한 연구는 분류모형과 같이 분석방법의 평가가 가능한 데이터마이닝 기법을 주로 이용함</p></li>
<li><p>다수의 환자자료를 확보하기 어려우며 환자 수에 비하여 유전자 수가 많아 모형 도출에 어려움이 있다는 한계점이 있음</p></li>
<li><p>마이크로어레이 실험은 과정이 복잡하고 정밀함이 요구되므로 실험결과의 표준화(normalization) 작업을 거쳐야 함</p>
<ul>
<li>표준화 작업은 분석자료를 얻기 위한 일종의 자료 전처리 과정(preprocessing)으로 전처리 과정을 위해 데이터마이닝에서 흔히 쓰이는 각종 탐색적 자료분석 기법을 사용함</li>
</ul></li>
</ul>
<p><br></p>
<p><br></p>
<!-------------------- End --------------->

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Introduction to Data Science.pdf", "Introduction to Data Science.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
